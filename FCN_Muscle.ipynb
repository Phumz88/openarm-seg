{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessica/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16400034169567473662\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11573238170\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 4981897453615498359\n",
      "physical_device_desc: \"device: 0, name: TITAN Xp, pci bus id: 0000:02:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(\"imported\")\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "sys.path.append('src/')\n",
    "import nn\n",
    "import process_data\n",
    "import nibabel as nib\n",
    "# import cv2\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy.sparse\n",
    "from scipy.misc import imrotate, imresize\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage import rotate\n",
    "from skimage import exposure\n",
    "from skimage.io import imread, imsave\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "print(local_device_protos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(L, class_labels):\n",
    "    \"\"\"\n",
    "    2D array (image) of segmentation labels -> .npy\n",
    "    # One Hot Encode the label 2d array -> .npy files with dim (h, w, len(class_labels))\n",
    "    # num classes will be 8? but currently dynamically allocated based on num colors in all scans.\n",
    "    \"\"\"\n",
    "    h, w = L.shape  # Should be 482, 395 (unless resized)\n",
    "    try:\n",
    "        encoded = np.array([list(map(class_labels.index, L.flatten()))])\n",
    "\n",
    "        L = encoded.reshape(h, w)\n",
    "\n",
    "        Lhot = np.zeros((L.shape[0], L.shape[1], len(class_labels)))\n",
    "        for i in range(L.shape[0]):\n",
    "            for j in range(L.shape[1]):\n",
    "                Lhot[i,j,L[i,j]] = 1\n",
    "        return Lhot  # Should be shape (482, 395, 9)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "def uncode_one_hot(npy_file):\n",
    "    \"\"\"\n",
    "    .npy file -> JPEG\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "#         if image.ndim == 2:\n",
    "#             plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()\n",
    "    \n",
    "def load_sparse_csr(filename):\n",
    "    # Sparse matrix reading function to read our raw .npz files\n",
    "    assert filename.endswith('.npz')\n",
    "    loader = np.load(filename)  # filename must end with .npz\n",
    "    return scipy.sparse.csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                      shape=loader['shape'])\n",
    "\n",
    "def get_raw_pixel_classes():\n",
    "    #import nibabel as nib\n",
    "    base_data_dir = \"/home/jessica/Documents/hart-seg-ml/allrawnifti\"\n",
    "    example_segmentation = os.path.join(base_data_dir, 'trial8_30_fs_seg_ak5_lh4_TRANS.nii')\n",
    "    scan_voxel = nib.load(example_segmentation)\n",
    "    struct_arr = scan_voxel.get_data()\n",
    "    n, h, w = struct_arr.shape\n",
    "    class_labels = list(np.unique(struct_arr))\n",
    "    \n",
    "def check_one_hot(encoded_img):\n",
    "    print(encoded_img.shape)\n",
    "    return np.all(np.sum(encoded_img, axis=2) == 1.)\n",
    "\n",
    "def batch_img_resize(images, h = 256, w = 256):\n",
    "    images_resized = np.zeros([0, newHeight, newWidth], dtype=np.uint8)\n",
    "    for  image in range(images.shape[0]):\n",
    "        temp = imresize(images[image], [h, w], 'nearest')\n",
    "        images_resized = np.append(images_resized, np.expand_dims(temp, axis=0), axis=0)\n",
    "    return images_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pixel_classes =[0, 100]  # Expected raw grayscale values for each pixel\n",
    "#directory = \"/Users/nozik/Documents/HARTresearch/allpreprocessed\"\n",
    "directory = \"/home/jessica/Documents/hart-seg-ml/fcn_test/artifacts_preprocessed\"\n",
    "filenames = []  # Stores all filenames\n",
    "raw_images = []  # Stores X (Raw cross section images as 2D np.ndarray)\n",
    "segmentations = []  # Stores Y (Labeled/Segmented image as one-hot-encoded NumClasses-D np.ndarray)\n",
    "h, w = 512, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jessica/Documents/hart-seg-ml/fcn_test/artifacts_preprocessed/trial18_90_fs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000_label.png 00000_raw.npz 00001_label.png 00001_raw.npz 00002_label.png 00002_raw.npz 00003_label.png 00003_raw.npz 00004_label.png 00004_raw.npz 00005_label.png 00005_raw.npz 00006_label.png 00006_raw.npz 00007_label.png 00007_raw.npz 00008_label.png 00008_raw.npz 00009_label.png 00009_raw.npz 00010_label.png 00010_raw.npz 00011_label.png 00011_raw.npz 00012_label.png 00012_raw.npz 00013_label.png 00013_raw.npz 00014_label.png 00014_raw.npz 00015_label.png 00015_raw.npz 00016_label.png 00016_raw.npz 00017_label.png 00017_raw.npz 00018_label.png 00018_raw.npz 00019_label.png 00019_raw.npz 00020_label.png 00020_raw.npz 00021_label.png 00021_raw.npz 00022_label.png 00022_raw.npz 00023_label.png 00023_raw.npz 00024_label.png 00024_raw.npz 00025_label.png 00025_raw.npz 00026_label.png 00026_raw.npz 00027_label.png 00027_raw.npz 00028_label.png 00028_raw.npz 00029_label.png 00029_raw.npz 00030_label.png 00030_raw.npz 00031_label.png 00031_raw.npz 00032_label.png 00032_raw.npz 00033_label.png 00033_raw.npz 00034_label.png 00034_raw.npz 00035_label.png 00035_raw.npz 00036_label.png 00036_raw.npz 00037_label.png 00037_raw.npz 00038_label.png 00038_raw.npz 00039_label.png 00039_raw.npz 00040_label.png 00040_raw.npz 00041_label.png 00041_raw.npz 00042_label.png 00042_raw.npz 00043_label.png 00043_raw.npz 00044_label.png 00044_raw.npz 00045_label.png 00045_raw.npz 00046_label.png 00046_raw.npz 00047_label.png 00047_raw.npz 00048_label.png 00048_raw.npz 00049_label.png 00049_raw.npz 00050_label.png 00050_raw.npz 00051_label.png 00051_raw.npz 00052_label.png 00052_raw.npz 00053_label.png 00053_raw.npz 00054_label.png 00054_raw.npz 00055_label.png 00055_raw.npz 00056_label.png 00056_raw.npz 00057_label.png 00057_raw.npz 00058_label.png 00058_raw.npz 00059_label.png 00059_raw.npz 00060_label.png 00060_raw.npz 00061_label.png 00061_raw.npz 00062_label.png 00062_raw.npz 00063_label.png 00063_raw.npz 00064_label.png 00064_raw.npz 00065_label.png 00065_raw.npz 00066_label.png 00066_raw.npz 00067_label.png 00067_raw.npz 00068_label.png 00068_raw.npz 00069_label.png 00069_raw.npz 00070_label.png 00070_raw.npz 00071_label.png 00071_raw.npz 00072_label.png 00072_raw.npz 00073_label.png 00073_raw.npz 00074_label.png 00074_raw.npz 00075_label.png 00075_raw.npz 00076_label.png 00076_raw.npz 00077_label.png 00077_raw.npz 00078_label.png 00078_raw.npz 00079_label.png 00079_raw.npz 00080_label.png 00080_raw.npz 00081_label.png 00081_raw.npz 00082_label.png 00082_raw.npz 00083_label.png 00083_raw.npz 00084_label.png 00084_raw.npz 00085_label.png 00085_raw.npz 00086_label.png 00086_raw.npz 00087_label.png 00087_raw.npz 00088_label.png 00088_raw.npz 00089_label.png 00089_raw.npz 00090_label.png 00090_raw.npz 00091_label.png 00091_raw.npz 00092_label.png 00092_raw.npz 00093_label.png 00093_raw.npz 00094_label.png 00094_raw.npz 00095_label.png 00095_raw.npz 00096_label.png 00096_raw.npz 00097_label.png 00097_raw.npz 00098_label.png 00098_raw.npz 00099_label.png 00099_raw.npz 00100_label.png 00100_raw.npz 00101_label.png 00101_raw.npz 00102_label.png 00102_raw.npz 00103_label.png 00103_raw.npz 00104_label.png 00104_raw.npz 00105_label.png 00105_raw.npz 00106_label.png 00106_raw.npz 00107_label.png 00107_raw.npz 00108_label.png 00108_raw.npz 00109_label.png 00109_raw.npz 00110_label.png 00110_raw.npz 00111_label.png 00111_raw.npz 00112_label.png 00112_raw.npz 00113_label.png 00113_raw.npz 00114_label.png 00114_raw.npz 00115_label.png 00115_raw.npz 00116_label.png 00116_raw.npz 00117_label.png 00117_raw.npz 00118_label.png 00118_raw.npz 00119_label.png 00119_raw.npz 00120_label.png 00120_raw.npz 00121_label.png 00121_raw.npz 00122_label.png 00122_raw.npz 00123_label.png 00123_raw.npz 00124_label.png 00124_raw.npz 00125_label.png 00125_raw.npz 00126_label.png 00126_raw.npz 00127_label.png 00127_raw.npz 00128_label.png 00128_raw.npz 00129_label.png 00129_raw.npz 00130_label.png 00130_raw.npz 00131_label.png 00131_raw.npz 00132_label.png 00132_raw.npz 00133_label.png 00133_raw.npz 00134_label.png 00134_raw.npz 00135_label.png 00135_raw.npz 00136_label.png 00136_raw.npz 00137_label.png 00137_raw.npz 00138_label.png 00138_raw.npz 00139_label.png 00139_raw.npz 00140_label.png 00140_raw.npz 00141_label.png 00141_raw.npz 00142_label.png 00142_raw.npz 00143_label.png 00143_raw.npz 00144_label.png 00144_raw.npz 00145_label.png 00145_raw.npz 00146_label.png 00146_raw.npz 00147_label.png 00147_raw.npz 00148_label.png 00148_raw.npz 00149_label.png 00149_raw.npz 00150_label.png 00150_raw.npz 00151_label.png 00151_raw.npz 00152_label.png 00152_raw.npz 00153_label.png 00153_raw.npz 00154_label.png 00154_raw.npz 00155_label.png 00155_raw.npz 00156_label.png 00156_raw.npz 00157_label.png 00157_raw.npz 00158_label.png 00158_raw.npz 00159_label.png 00159_raw.npz 00160_label.png 00160_raw.npz 00161_label.png 00161_raw.npz 00162_label.png 00162_raw.npz 00163_label.png 00163_raw.npz 00164_label.png 00164_raw.npz 00165_label.png 00165_raw.npz 00166_label.png 00166_raw.npz 00167_label.png 00167_raw.npz 00168_label.png 00168_raw.npz 00169_label.png 00169_raw.npz 00170_label.png 00170_raw.npz 00171_label.png 00171_raw.npz 00172_label.png 00172_raw.npz 00173_label.png 00173_raw.npz 00174_label.png 00174_raw.npz 00175_label.png 00175_raw.npz 00176_label.png 00176_raw.npz 00177_label.png 00177_raw.npz 00178_label.png 00178_raw.npz 00179_label.png 00179_raw.npz 00180_label.png 00180_raw.npz 00181_label.png 00181_raw.npz 00182_label.png 00182_raw.npz 00183_label.png 00183_raw.npz 00184_label.png 00184_raw.npz 00185_label.png 00185_raw.npz 00186_label.png 00186_raw.npz 00187_label.png 00187_raw.npz 00188_label.png 00188_raw.npz 00189_label.png 00189_raw.npz 00190_label.png 00190_raw.npz 00191_label.png 00191_raw.npz 00192_label.png 00192_raw.npz 00193_label.png 00193_raw.npz 00194_label.png 00194_raw.npz 00195_label.png 00195_raw.npz 00196_label.png 00196_raw.npz 00197_label.png 00197_raw.npz 00198_label.png 00198_raw.npz 00199_label.png 00199_raw.npz 00200_label.png 00200_raw.npz 00201_label.png 00201_raw.npz 00202_label.png 00202_raw.npz 00203_label.png 00203_raw.npz 00204_label.png 00204_raw.npz 00205_label.png 00205_raw.npz 00206_label.png 00206_raw.npz 00207_label.png 00207_raw.npz 00208_label.png 00208_raw.npz 00209_label.png 00209_raw.npz 00210_label.png 00210_raw.npz 00211_label.png 00211_raw.npz 00212_label.png 00212_raw.npz 00213_label.png 00213_raw.npz 00214_label.png 00214_raw.npz 00215_label.png 00215_raw.npz 00216_label.png 00216_raw.npz 00217_label.png 00217_raw.npz 00218_label.png 00218_raw.npz 00219_label.png 00219_raw.npz 00220_label.png 00220_raw.npz 00221_label.png 00221_raw.npz 00222_label.png 00222_raw.npz 00223_label.png 00223_raw.npz 00224_label.png 00224_raw.npz 00225_label.png 00225_raw.npz 00226_label.png 00226_raw.npz 00227_label.png 00227_raw.npz 00228_label.png 00228_raw.npz 00229_label.png 00229_raw.npz 00230_label.png 00230_raw.npz 00231_label.png 00231_raw.npz 00232_label.png 00232_raw.npz 00233_label.png 00233_raw.npz 00234_label.png 00234_raw.npz 00235_label.png 00235_raw.npz 00236_label.png 00236_raw.npz 00237_label.png 00237_raw.npz 00238_label.png 00238_raw.npz 00239_label.png 00239_raw.npz 00240_label.png 00240_raw.npz 00241_label.png 00241_raw.npz 00242_label.png 00242_raw.npz 00243_label.png 00243_raw.npz 00244_label.png 00244_raw.npz 00245_label.png 00245_raw.npz 00246_label.png 00246_raw.npz 00247_label.png 00247_raw.npz 00248_label.png 00248_raw.npz 00249_label.png 00249_raw.npz 00250_label.png 00250_raw.npz 00251_label.png 00251_raw.npz 00252_label.png 00252_raw.npz 00253_label.png 00253_raw.npz 00254_label.png 00254_raw.npz 00255_label.png 00255_raw.npz 00256_label.png 00256_raw.npz 00257_label.png 00257_raw.npz 00258_label.png 00258_raw.npz 00259_label.png 00259_raw.npz 00260_label.png 00260_raw.npz 00261_label.png 00261_raw.npz 00262_label.png 00262_raw.npz 00263_label.png 00263_raw.npz 00264_label.png 00264_raw.npz 00265_label.png 00265_raw.npz 00266_label.png 00266_raw.npz 00267_label.png 00267_raw.npz 00268_label.png 00268_raw.npz 00269_label.png 00269_raw.npz 00270_label.png 00270_raw.npz 00271_label.png 00271_raw.npz 00272_label.png 00272_raw.npz 00273_label.png "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00273_raw.npz 00274_label.png 00274_raw.npz 00275_label.png 00275_raw.npz 00276_label.png 00276_raw.npz 00277_label.png 00277_raw.npz 00278_label.png 00278_raw.npz 00279_label.png 00279_raw.npz 00280_label.png 00280_raw.npz 00281_label.png 00281_raw.npz 00282_label.png 00282_raw.npz 00283_label.png 00283_raw.npz 00284_label.png 00284_raw.npz 00285_label.png 00285_raw.npz 00286_label.png 00286_raw.npz 00287_label.png 00287_raw.npz 00288_label.png 00288_raw.npz 00289_label.png 00289_raw.npz 00290_label.png 00290_raw.npz 00291_label.png 00291_raw.npz 00292_label.png 00292_raw.npz 00293_label.png 00293_raw.npz 00294_label.png 00294_raw.npz 00295_label.png 00295_raw.npz 00296_label.png 00296_raw.npz 00297_label.png 00297_raw.npz 00298_label.png 00298_raw.npz 00299_label.png 00299_raw.npz 00300_label.png 00300_raw.npz 00301_label.png 00301_raw.npz 00302_label.png 00302_raw.npz 00303_label.png 00303_raw.npz 00304_label.png 00304_raw.npz 00305_label.png 00305_raw.npz 00306_label.png 00306_raw.npz 00307_label.png 00307_raw.npz 00308_label.png 00308_raw.npz 00309_label.png 00309_raw.npz 00310_label.png 00310_raw.npz 00311_label.png 00311_raw.npz 00312_label.png 00312_raw.npz 00313_label.png 00313_raw.npz 00314_label.png 00314_raw.npz 00315_label.png 00315_raw.npz 00316_label.png 00316_raw.npz 00317_label.png 00317_raw.npz 00318_label.png 00318_raw.npz 00319_label.png 00319_raw.npz 00320_label.png 00320_raw.npz 00321_label.png 00321_raw.npz 00322_label.png 00322_raw.npz 00323_label.png 00323_raw.npz 00324_label.png 00324_raw.npz 00325_label.png 00325_raw.npz 00326_label.png 00326_raw.npz 00327_label.png 00327_raw.npz 00328_label.png 00328_raw.npz 00329_label.png 00329_raw.npz 00330_label.png 00330_raw.npz 00331_label.png 00331_raw.npz 00332_label.png 00332_raw.npz 00333_label.png 00333_raw.npz 00334_label.png 00334_raw.npz 00335_label.png 00335_raw.npz 00336_label.png 00336_raw.npz 00337_label.png 00337_raw.npz 00338_label.png 00338_raw.npz 00339_label.png 00339_raw.npz 00340_label.png 00340_raw.npz 00341_label.png 00341_raw.npz 00342_label.png 00342_raw.npz 00343_label.png 00343_raw.npz 00344_label.png 00344_raw.npz 00345_label.png 00345_raw.npz 00346_label.png 00346_raw.npz 00347_label.png 00347_raw.npz 00348_label.png 00348_raw.npz 00349_label.png 00349_raw.npz 00350_label.png 00350_raw.npz 00351_label.png 00351_raw.npz 00352_label.png 00352_raw.npz 00353_label.png 00353_raw.npz 00354_label.png 00354_raw.npz 00355_label.png 00355_raw.npz 00356_label.png 00356_raw.npz 00357_label.png 00357_raw.npz 00358_label.png 00358_raw.npz 00359_label.png 00359_raw.npz 00360_label.png 00360_raw.npz 00361_label.png 00361_raw.npz 00362_label.png 00362_raw.npz 00363_label.png 00363_raw.npz 00364_label.png 00364_raw.npz 00365_label.png 00365_raw.npz 00366_label.png 00366_raw.npz 00367_label.png 00367_raw.npz 00368_label.png 00368_raw.npz 00369_label.png 00369_raw.npz 00370_label.png 00370_raw.npz 00371_label.png 00371_raw.npz 00372_label.png 00372_raw.npz 00373_label.png 00373_raw.npz 00374_label.png 00374_raw.npz 00375_label.png 00375_raw.npz 00376_label.png 00376_raw.npz 00377_label.png 00377_raw.npz 00378_label.png 00378_raw.npz 00379_label.png 00379_raw.npz 00380_label.png 00380_raw.npz 00381_label.png 00381_raw.npz 00382_label.png 00382_raw.npz 00383_label.png 00383_raw.npz 00384_label.png 00384_raw.npz 00385_label.png 00385_raw.npz 00386_label.png 00386_raw.npz 00387_label.png 00387_raw.npz 00388_label.png 00388_raw.npz 00389_label.png 00389_raw.npz 00390_label.png 00390_raw.npz 00391_label.png 00391_raw.npz 00392_label.png 00392_raw.npz 00393_label.png 00393_raw.npz 00394_label.png 00394_raw.npz 00395_label.png 00395_raw.npz 00396_label.png 00396_raw.npz 00397_label.png 00397_raw.npz 00398_label.png 00398_raw.npz 00399_label.png 00399_raw.npz 00400_label.png 00400_raw.npz 00401_label.png 00401_raw.npz 00402_label.png 00402_raw.npz 00403_label.png 00403_raw.npz 00404_label.png 00404_raw.npz 00405_label.png 00405_raw.npz 00406_label.png 00406_raw.npz 00407_label.png 00407_raw.npz 00408_label.png 00408_raw.npz 00409_label.png 00409_raw.npz 00410_label.png 00410_raw.npz 00411_label.png 00411_raw.npz 00412_label.png 00412_raw.npz 00413_label.png 00413_raw.npz 00414_label.png 00414_raw.npz 00415_label.png 00415_raw.npz 00416_label.png 00416_raw.npz 00417_label.png 00417_raw.npz 00418_label.png 00418_raw.npz 00419_label.png 00419_raw.npz 00420_label.png 00420_raw.npz 00421_label.png 00421_raw.npz 00422_label.png 00422_raw.npz 00423_label.png 00423_raw.npz 00424_label.png 00424_raw.npz 00425_label.png 00425_raw.npz 00426_label.png 00426_raw.npz 00427_label.png 00427_raw.npz 00428_label.png 00428_raw.npz 00429_label.png 00429_raw.npz 00430_label.png 00430_raw.npz 00431_label.png 00431_raw.npz 00432_label.png 00432_raw.npz 00433_label.png 00433_raw.npz 00434_label.png 00434_raw.npz 00435_label.png 00435_raw.npz 00436_label.png 00436_raw.npz 00437_label.png 00437_raw.npz 00438_label.png 00438_raw.npz 00439_label.png 00439_raw.npz 00440_label.png 00440_raw.npz 00441_label.png 00441_raw.npz 00442_label.png 00442_raw.npz 00443_label.png 00443_raw.npz 00444_label.png 00444_raw.npz 00445_label.png 00445_raw.npz 00446_label.png 00446_raw.npz 00447_label.png 00447_raw.npz 00448_label.png 00448_raw.npz 00449_label.png 00449_raw.npz 00450_label.png 00450_raw.npz 00451_label.png 00451_raw.npz 00452_label.png 00452_raw.npz 00453_label.png 00453_raw.npz 00454_label.png 00454_raw.npz 00455_label.png 00455_raw.npz 00456_label.png 00456_raw.npz 00457_label.png 00457_raw.npz 00458_label.png 00458_raw.npz 00459_label.png 00459_raw.npz 00460_label.png 00460_raw.npz 00461_label.png 00461_raw.npz 00462_label.png 00462_raw.npz 00463_label.png 00463_raw.npz 00464_label.png 00464_raw.npz 00465_label.png 00465_raw.npz 00466_label.png 00466_raw.npz 00467_label.png 00467_raw.npz 00468_label.png 00468_raw.npz 00469_label.png 00469_raw.npz 00470_label.png 00470_raw.npz 00471_label.png 00471_raw.npz 00472_label.png 00472_raw.npz 00473_label.png 00473_raw.npz 00474_label.png 00474_raw.npz 00475_label.png 00475_raw.npz 00476_label.png 00476_raw.npz 00477_label.png 00477_raw.npz 00478_label.png 00478_raw.npz 00479_label.png 00479_raw.npz 00480_label.png 00480_raw.npz 00481_label.png 00481_raw.npz 00482_label.png 00482_raw.npz 00483_label.png 00483_raw.npz 00484_label.png 00484_raw.npz 00485_label.png 00485_raw.npz 00486_label.png 00486_raw.npz 00487_label.png 00487_raw.npz 00488_label.png 00488_raw.npz 00489_label.png 00489_raw.npz 00490_label.png 00490_raw.npz 00491_label.png 00491_raw.npz 00492_label.png 00492_raw.npz 00493_label.png 00493_raw.npz 00494_label.png 00494_raw.npz 00495_label.png 00495_raw.npz 00496_label.png 00496_raw.npz 00497_label.png 00497_raw.npz 00498_label.png 00498_raw.npz 00499_label.png 00499_raw.npz 00500_label.png 00500_raw.npz 00501_label.png 00501_raw.npz 00502_label.png 00502_raw.npz 00503_label.png 00503_raw.npz 00504_label.png 00504_raw.npz 00505_label.png 00505_raw.npz 00506_label.png 00506_raw.npz 00507_label.png 00507_raw.npz 00508_label.png 00508_raw.npz 00509_label.png 00509_raw.npz 00510_label.png 00510_raw.npz 00511_label.png 00511_raw.npz 00512_label.png 00512_raw.npz 00513_label.png 00513_raw.npz 00514_label.png 00514_raw.npz 00515_label.png 00515_raw.npz 00516_label.png 00516_raw.npz 00517_label.png 00517_raw.npz 00518_label.png 00518_raw.npz 00519_label.png 00519_raw.npz 00520_label.png 00520_raw.npz 00521_label.png 00521_raw.npz 00522_label.png 00522_raw.npz 00523_label.png 00523_raw.npz 00524_label.png 00524_raw.npz 00525_label.png 00525_raw.npz 00526_label.png 00526_raw.npz 00527_label.png 00527_raw.npz 00528_label.png 00528_raw.npz 00529_label.png 00529_raw.npz 00530_label.png 00530_raw.npz 00531_label.png 00531_raw.npz 00532_label.png 00532_raw.npz 00533_label.png 00533_raw.npz 00534_label.png 00534_raw.npz 00535_label.png 00535_raw.npz 00536_label.png 00536_raw.npz 00537_label.png 00537_raw.npz 00538_label.png 00538_raw.npz 00539_label.png 00539_raw.npz 00540_label.png 00540_raw.npz 00541_label.png 00541_raw.npz 00542_label.png 00542_raw.npz 00543_label.png 00543_raw.npz 00544_label.png 00544_raw.npz 00545_label.png 00545_raw.npz 00546_label.png 00546_raw.npz 00547_label.png "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00547_raw.npz 00548_label.png 00548_raw.npz 00549_label.png 00549_raw.npz 00550_label.png 00550_raw.npz 00551_label.png 00551_raw.npz 00552_label.png 00552_raw.npz 00553_label.png 00553_raw.npz 00554_label.png 00554_raw.npz 00555_label.png 00555_raw.npz 00556_label.png 00556_raw.npz 00557_label.png 00557_raw.npz 00558_label.png 00558_raw.npz 00559_label.png 00559_raw.npz 00560_label.png 00560_raw.npz 00561_label.png 00561_raw.npz 00562_label.png 00562_raw.npz 00563_label.png 00563_raw.npz 00564_label.png 00564_raw.npz 00565_label.png 00565_raw.npz 00566_label.png 00566_raw.npz 00567_label.png 00567_raw.npz 00568_label.png 00568_raw.npz 00569_label.png 00569_raw.npz 00570_label.png 00570_raw.npz 00571_label.png 00571_raw.npz 00572_label.png 00572_raw.npz 00573_label.png 00573_raw.npz 00574_label.png 00574_raw.npz 00575_label.png 00575_raw.npz 00576_label.png 00576_raw.npz 00577_label.png 00577_raw.npz 00578_label.png 00578_raw.npz 00579_label.png 00579_raw.npz 00580_label.png 00580_raw.npz 00581_label.png 00581_raw.npz 00582_label.png 00582_raw.npz 00583_label.png 00583_raw.npz 00584_label.png 00584_raw.npz 00585_label.png 00585_raw.npz 00586_label.png 00586_raw.npz 00587_label.png 00587_raw.npz 00588_label.png 00588_raw.npz 00589_label.png 00589_raw.npz 00590_label.png 00590_raw.npz 00591_label.png 00591_raw.npz 00592_label.png 00592_raw.npz 00593_label.png 00593_raw.npz 00594_label.png 00594_raw.npz 00595_label.png 00595_raw.npz 00596_label.png 00596_raw.npz 00597_label.png 00597_raw.npz 00598_label.png 00598_raw.npz 00599_label.png 00599_raw.npz 00600_label.png 00600_raw.npz 00601_label.png 00601_raw.npz 00602_label.png 00602_raw.npz 00603_label.png 00603_raw.npz 00604_label.png 00604_raw.npz 00605_label.png 00605_raw.npz 00606_label.png 00606_raw.npz 00607_label.png 00607_raw.npz 00608_label.png 00608_raw.npz 00609_label.png 00609_raw.npz 00610_label.png 00610_raw.npz 00611_label.png 00611_raw.npz 00612_label.png 00612_raw.npz 00613_label.png 00613_raw.npz 00614_label.png 00614_raw.npz 00615_label.png 00615_raw.npz 00616_label.png 00616_raw.npz 00617_label.png 00617_raw.npz 00618_label.png 00618_raw.npz 00619_label.png 00619_raw.npz 00620_label.png 00620_raw.npz 00621_label.png 00621_raw.npz 00622_label.png 00622_raw.npz 00623_label.png 00623_raw.npz 00624_label.png 00624_raw.npz 00625_label.png 00625_raw.npz 00626_label.png 00626_raw.npz 00627_label.png 00627_raw.npz 00628_label.png 00628_raw.npz 00629_label.png 00629_raw.npz 00630_label.png 00630_raw.npz 00631_label.png 00631_raw.npz 00632_label.png 00632_raw.npz 00633_label.png 00633_raw.npz 00634_label.png 00634_raw.npz 00635_label.png 00635_raw.npz 00636_label.png 00636_raw.npz 00637_label.png 00637_raw.npz 00638_label.png 00638_raw.npz 00639_label.png 00639_raw.npz 00640_label.png 00640_raw.npz 00641_label.png 00641_raw.npz 00642_label.png 00642_raw.npz 00643_label.png 00643_raw.npz 00644_label.png 00644_raw.npz 00645_label.png 00645_raw.npz 00646_label.png 00646_raw.npz 00647_label.png 00647_raw.npz \n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(directory):\n",
    "    class_labels = set()\n",
    "    if not folder.startswith('.'):\n",
    "        path = os.path.join(directory, folder)\n",
    "        print(path)\n",
    "        files = sorted([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')])\n",
    "        \n",
    "        # Class label sanity check\n",
    "#         for f in files:\n",
    "#             if 'label' in f:\n",
    "#                 img = imread(os.path.join(path, f), flatten=True)\n",
    "#                 class_labels = class_labels.union(np.unique(img))\n",
    "#         if not class_labels.issubset(raw_pixel_classes):\n",
    "#             print(\"Class labels found in labeled images do not match the expected classes for scan {}\".format(folder))\n",
    "#             print(\"Expected {}\".format(raw_pixel_classes))\n",
    "#             print(\"Received {}\".format(sorted(class_labels)))\n",
    "#             break\n",
    "        \n",
    "        # Sanity image read and show some images in pairs (play with the range inputs)\n",
    "#         for f in range(0, len(files), 2):\n",
    "#             label_name = files[f]\n",
    "#             raw_name = files[f+1]\n",
    "#             label_img = imread(os.path.join(path, label_name), flatten=True)\n",
    "#             raw_img = load_sparse_csr(os.path.join(path, raw_name)).toarray()  # Load sparse csr mat img -> to 2D numpy array\n",
    "#             show_images([label_img, raw_img], titles=[label_name, raw_name])\n",
    "        \n",
    "        # Set up Datasets (X, Y) pairs of data ->\n",
    "        # files are sorted by the name: either '#_label' or '#_raw'\n",
    "        for f in files:\n",
    "            print(f, end=' ')\n",
    "            if 'label' in f:\n",
    "                img = imread(os.path.join(path, f), flatten=True)\n",
    "            else:\n",
    "                img = load_sparse_csr(os.path.join(path, f)).toarray()            \n",
    "            \n",
    "#             imresize(seg[:,:,1],(h,w), interp='nearest')/255.0\n",
    "            npad = ((15, 15), (58, 59))  # Pads to size 512, 512\n",
    "            img = np.pad(img, pad_width=npad, mode='constant', constant_values=0)\n",
    "            if 'raw' in f:\n",
    "                raw_images.append(img)\n",
    "            elif 'label' in f:\n",
    "                encoded_img = one_hot_encode(img, raw_pixel_classes)\n",
    "                segmentations.append(encoded_img)\n",
    "            filenames.append(os.path.join(folder, f))\n",
    "    print(\"\")\n",
    "            \n",
    "\n",
    "# print(filenames)\n",
    "\n",
    "            \n",
    "# images = np.array(images)\n",
    "# segmentations = np.round(np.array(segmentations)).astype('uint8')\n",
    "\n",
    "\n",
    "# study_num = int(2)\n",
    "# train_lst = np.load('data/splits/train_lst_' + str(study_num) + '.npy')\n",
    "# val_lst = np.load('data/splits/val_lst_' + str(study_num) + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# raw_90_deg_training = np.array(raw_images)\n",
    "# seg_90_deg_training = np.array(segmentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training, Cross Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(raw_images), len(segmentations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Same Scan cannot be used across Train, Validation and Test sets\n",
    "TODO: Different weight conditions and angles may be used to segment other raw_scans\n",
    "TODO: Bounding Box, image resizing, padding edges\n",
    "\"\"\"\n",
    "# raw_images holds our X data\n",
    "# segmentations holds out Y data\n",
    "x_train, y_train = [], []\n",
    "x_val, y_val = [], []\n",
    "x_test, y_test = [], []\n",
    "\n",
    "percent_train, percent_val, percent_test = 60, 10, 30\n",
    "num_train = np.round(len(raw_images) * percent_train/100).astype(np.int)\n",
    "num_val = np.round(num_train + len(raw_images) * percent_val/100).astype(np.int)\n",
    "num_test = np.round(num_val + len(raw_images) * percent_test/100).astype(np.int)\n",
    "\n",
    "print(\"num_train: \", num_train, \"num_val: \", num_val, \"num_test: \", num_test)\n",
    "\n",
    "assert len(raw_images) == len(segmentations)\n",
    "rand_indices = list(np.random.choice(len(raw_images), len(raw_images), replace=False))\n",
    "\n",
    "for i in rand_indices[:num_train]:\n",
    "    x_train.append(raw_images[i])\n",
    "    y_train.append(segmentations[i])\n",
    "for j in rand_indices[num_train:num_val]:\n",
    "    x_val.append(raw_images[j])\n",
    "    y_val.append(segmentations[j])\n",
    "for k in rand_indices[num_val:num_test]:\n",
    "    x_test.append(raw_images[k])\n",
    "    y_test.append(segmentations[k])\n",
    "\n",
    "        \n",
    "x_train = np.array(x_train).reshape((len(x_train), h, w, 1))\n",
    "x_test = np.array(x_test).reshape((len(x_test), h, w, 1))\n",
    "x_val = np.array(x_val).reshape((len(x_val), h, w, 1))\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "# Fix data padding to create square 482 by 482 matrix\n",
    "# npad = ((0, 0), (15, 15), (58, 59), (0, 0))\n",
    "# x_train = np.pad(x_train, pad_width=npad, mode='constant', constant_values=0)\n",
    "# x_test = np.pad(x_test, pad_width=npad, mode='constant', constant_values=0)\n",
    "# y_train = np.pad(y_train, pad_width=npad, mode='constant', constant_values=0)\n",
    "# y_test = np.pad(y_test, pad_width=npad, mode='constant', constant_values=0)\n",
    "\n",
    "# print()\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "\n",
    "#     image = imresize(imread(directory + folder + '/' + folder + '.jpg', flatten = True),(h, w))\n",
    "#     images.append(image)\n",
    "#     filenames.append(folder)\n",
    "#     seg = np.load(directory+folder+'/seg.npy')\n",
    "#     temp = np.zeros((h,w,1))\n",
    "#     temp[:,:,1] = imresize(seg[:,:,1],(h,w), interp='nearest')/255.0\n",
    "#     segmentations.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN-8s Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(object):\n",
    "    def __init__(self, mean, weight_decay, learning_rate, label_dim=8, dropout=0.9, h=512, w=512):\n",
    "        self.NUM_CLASSES = 2 # TODO: HARDCODE THIS\n",
    "        self.label_dim = label_dim\n",
    "        self.weight_decay = weight_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.x_train = tf.placeholder(tf.float32, [None, h, w, 1])\n",
    "        self.y_train = tf.placeholder(tf.float32, [None, h, w, 2])\n",
    "        self.x_test = tf.placeholder(tf.float32, [None, h, w, 1])\n",
    "        self.y_test = tf.placeholder(tf.float32, [None, h, w, 2])\n",
    "\n",
    "        self.output = self.fcn(self.x_train, mean, keep_prob=self.dropout)\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.output, labels=self.y_train))\n",
    "        self.opt = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "        \n",
    "        self.pred = self.fcn(self.x_test, mean, reuse=True, keep_prob=.8)\n",
    "        self.loss_summary = tf.summary.scalar('loss', self.loss)\n",
    "\n",
    "    def fcn(self, input, mean, keep_prob = 0.9, reuse = True):\n",
    "        input = input - mean  # Demean\n",
    "\n",
    "        pool_ = lambda x: nn.max_pool(x, 2, 2)\n",
    "        conv_ = lambda x, output_depth, name, padding='SAME', relu=True, filter_size=3: nn.conv(x, filter_size,\n",
    "                                                                                                output_depth, 1,\n",
    "                                                                                                self.weight_decay,\n",
    "                                                                                                name=name,\n",
    "                                                                                                padding=padding,\n",
    "                                                                                                relu=relu)\n",
    "        deconv_ = lambda x, output_depth, name: nn.deconv(x, 2, output_depth, 2, self.weight_decay, name=name)\n",
    "\n",
    "        # construct fully convolutional layers\n",
    "        \n",
    "        print(input.get_shape())\n",
    "#         with tf.variable_scope(\"conv1_1\") as scope:\n",
    "        conv_1_1 = conv_(input, 64, 'conv1_1')\n",
    "        conv_1_2 = conv_(conv_1_1, 64, 'conv1_2')\n",
    "\n",
    "        pool_1 = pool_(conv_1_2)\n",
    "\n",
    "        conv_2_1 = conv_(pool_1, 128, 'conv2_1')\n",
    "        conv_2_2 = conv_(conv_2_1, 128, 'conv2_2')\n",
    "\n",
    "        pool_2 = pool_(conv_2_2)\n",
    "        print(pool_2.get_shape())\n",
    "\n",
    "        conv_3_1 = conv_(pool_2, 256, 'conv3_1')\n",
    "        conv_3_2 = conv_(conv_3_1, 256, 'conv3_2')\n",
    "\n",
    "        self.pool_3 = pool_(conv_3_2)\n",
    "        print(self.pool_3.get_shape())\n",
    "\n",
    "        conv_4_1 = conv_(self.pool_3, 512, 'conv4_1')\n",
    "        conv_4_2 = conv_(conv_4_1, 512, 'conv4_2')\n",
    "\n",
    "        self.pool_4 = pool_(conv_4_2)\n",
    "        print(self.pool_4.get_shape())\n",
    "\n",
    "        conv_5_1 = conv_(self.pool_4, 4096, 'conv5_1')\n",
    "        conv_5_2 = conv_(conv_5_1, 4096, 'conv5_2')\n",
    "\n",
    "        pool_5 = pool_(conv_5_2)\n",
    "        print(pool_5.get_shape())\n",
    "        \n",
    "\n",
    "        # weight is the equivalent to the kernel creation\n",
    "        # tf.nn.conv2d parameters: input, filter, strides, padding, \n",
    "\n",
    "        w6 = tf.Variable(tf.random_normal([16, 16, 4096, 4096]), name=\"weight6\")\n",
    "        b6 = tf.Variable(tf.zeros([4096]), name=\"bias6\")\n",
    "        conv_6 = tf.nn.conv2d(pool_5, w6, [1, 1, 1, 1], padding=\"SAME\")\n",
    "        b6_layer = tf.nn.bias_add(conv_6, b6)\n",
    "        relu_6 = tf.nn.relu(conv_6, name=\"relu6\")\n",
    "        relu_dropout6 = tf.nn.dropout(relu_6, keep_prob=keep_prob)\n",
    "\n",
    "        w7 = tf.Variable(tf.random_normal([1, 1, 4096, 4096]), name=\"weight7\")\n",
    "        b7 = tf.Variable(tf.zeros([4096]), name=\"bias7\")\n",
    "        conv7 = tf.nn.conv2d(relu_dropout6, w7, [1, 1, 1, 1], padding=\"SAME\") \n",
    "        b7_layer = tf.nn.bias_add(conv7, b7)\n",
    "        relu7 = tf.nn.relu(conv7, name=\"relu7\")\n",
    "        relu_dropout7 = tf.nn.dropout(relu7, keep_prob=keep_prob)\n",
    "        print(relu_dropout7.get_shape())\n",
    "        \n",
    "        \n",
    "        # begin decoder, start with 1x1 convolution on conv7\n",
    "#         w8 = tf.Variable(tf.random_normal([1, 1, 4096, self.NUM_CLASSES]),\n",
    "#                                    name=\"W8\")\n",
    "#         b8 = tf.Variable(tf.zeros([self.NUM_CLASSES]), name=\"b8\")\n",
    "#         conv8 = tf.nn.conv2d(relu_dropout7, w8, [1, 1, 1, 1], padding=\"SAME\")  \n",
    "#         b8_layer = tf.nn.bias_add(conv8, b8)\n",
    "        b8_layer = tf.layers.conv2d(relu_dropout7, self.NUM_CLASSES, kernel_size=1, strides=(1, 1), padding=\"SAME\", name=\"b8_layer\")\n",
    "        print(b8_layer.get_shape())\n",
    "        # skip layer 1: add compressed conv7 layer to pool4\n",
    "        \n",
    "        up1 = tf.layers.conv2d_transpose(b8_layer, 512, kernel_size=4, strides=2, name=\"up1\", padding=\"SAME\")\n",
    "        print(up1.get_shape())\n",
    "        print(self.pool_4.get_shape())\n",
    "        fuse1 = tf.add(up1, self.pool_4)\n",
    "        \n",
    "        up2 = tf.layers.conv2d_transpose(fuse1, 256, kernel_size=4, strides=2, name=\"up2\", padding=\"SAME\")\n",
    "        fuse2 = tf.add(up2, self.pool_3)\n",
    "\n",
    "        output = tf.layers.conv2d_transpose(fuse2, self.NUM_CLASSES, kernel_size=16, strides=8, name=\"output\", padding=\"SAME\")\n",
    "        return output\n",
    "    \n",
    "    \n",
    "#         deconv_shape1 = pool_4.get_shape()\n",
    "#         # 4x4 upscaling kernel with stride \n",
    "#         W_t1 = tf.Variable(tf.random_normal([4, 4, deconv_shape1[3].value, self.NUM_CLASSES]), name=\"W_t1\")\n",
    "#         b_t1 = tf.Variable(tf.zeros([deconv_shape1[3].value]), name=\"bt1\")\n",
    "#         conv_t1 = tf.layers.conv2d_transpose(conv8, W_t1, tf.shape(pool_4), [2, 2, 1, 1])\n",
    "#         bt1_layer = tf.nn.bias_add(conv_t1, b_t1)\n",
    "#         fuse_1 = tf.add(conv_t1, pool_4, name=\"fuse_1\")\n",
    "#         print(tf.shape(fuse_1))\n",
    "\n",
    "        # skip layer 2: add skip layer 1 with pool3\n",
    "    #         deconv_shape2 = pool_3.get_shape()\n",
    "#         W_t2 = tf.Variable(tf.random_normal([4, 4, deconv_shape2[3].value, deconv_shape1[3].value]), name=\"W_t2\")\n",
    "#         b_t2 = tf.Variable(tf.zeros([deconv_shape2[3].value]), name=\"b_t2\")\n",
    "#         conv_t2 = tf.nn.conv2d_transpose(fuse_1, W_t2, tf.shape(pool_3), [2, 2, 1, 1])\n",
    "#         bt2_layer = tf.nn.bias_add(conv_t2, b_t2)\n",
    "#         fuse_2 = tf.add(conv_t2, pool_3, name=\"fuse_2\")\n",
    "#         print(tf.shape(fuse_2))\n",
    "#         print(self.label_dim)\n",
    "#         shape = tf.shape(self.label_dim)\n",
    "#         print(shape)\n",
    "#         W_t3 = tf.Variable(tf.random_normal([16, 16, self.NUM_CLASSES, deconv_shape2[3].value]), name=\"W_t3\")\n",
    "#         b_t3 = tf.Variable(tf.zeros([self.NUM_CLASSES]), name=\"b_t3\")\n",
    "\n",
    "#         prob = tf.nn.conv2d_transpose(fuse_2, W_t3, [1, h, w, self.NUM_CLASSES], [8, 8, 1, 1])\n",
    "#         prob_bias = tf.nn.bias_add(prob, b_t3)\n",
    "#         pred = tf.argmax(prob, dimension=3, name=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Hyperparameters\n",
    "mean = 0\n",
    "weight_decay = 1e-6\n",
    "learning_rate = 1e-4\n",
    "label_dim = 8\n",
    "maxout = False\n",
    "\n",
    "# Create TF graph and initialize variables\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "model = FCN(mean, weight_decay, learning_rate, label_dim , dropout = 0.9)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore old model\n",
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess, '/media/deoraid03/jeff/models/a4c_experiments/deep_256_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "nn.train(sess, model, x_train, y_train, x_val, y_val, epochs = 1000, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# IOU Accuracies for each label\n",
    "print(nn.validate(sess, model, x_val, y_val))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "models_dir = '/home/jessica/Documents/hart-seg-ml/artifacts_raw_and_results'\n",
    "model_name = 'model'\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join(os.path.join(models_dir, model_name), model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "saver = tf.train.import_meta_graph('/home/jessica/Documents/hart-seg-ml/models/test_june18/test_june18.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./models/test_june18'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/jessica/Documents/hart-seg-ml/test\"\n",
    "filenames = []  # Stores all filenames\n",
    "raw_images = []  # Stores X (Raw cross section images as 2D np.ndarray)\n",
    "segmentations = []  # Stores Y (Labeled/Segmented image as one-hot-encoded NumClasses-D np.ndarray)\n",
    "\n",
    "for folder in os.listdir(directory):\n",
    "    if not folder.startswith('.'):\n",
    "        path = os.path.join(directory, folder)\n",
    "        files = sorted([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')])\n",
    "        \n",
    "        for f in files:\n",
    "            print(f, end=' ')\n",
    "            if 'label' in f:\n",
    "                img = imread(os.path.join(path, f), flatten=False)\n",
    "            else:\n",
    "                img = load_sparse_csr(os.path.join(path, f)).toarray()            \n",
    "            \n",
    "#             imresize(seg[:,:,1],(h,w), interp='nearest')/255.0\n",
    "            npad = ((15, 15), (58, 59))  # Pads to size 512, 512\n",
    "            img = np.pad(img, pad_width=npad, mode='constant', constant_values=0)\n",
    "            if 'raw' in f:\n",
    "                raw_images.append(img)\n",
    "            elif 'label' in f:\n",
    "                # encoded_img = one_hot_encode(img, raw_pixel_classes)\n",
    "                # segmentations.append(encoded_img)\n",
    "                segmentations.append(img)\n",
    "            filenames.append(os.path.join(folder, f))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_imgs_arr = np.array(raw_images)\n",
    "raw_imgs_arr = np.expand_dims(raw_imgs_arr, axis=3)\n",
    "\n",
    "seg_imgs_arr = np.array(segmentations)\n",
    "#seg_imgs_arr = np.expand_dims(seg_imgs_arr, axis=3)\n",
    "\n",
    "\n",
    "\n",
    "print(raw_imgs_arr.shape)\n",
    "\n",
    "print(seg_imgs_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cross_sec(x, model, sess):\n",
    "    prediction = model.predict(sess, x)\n",
    "    pred_classes = np.argmax(prediction[0], axis=2)\n",
    "    return pred_classes\n",
    "\n",
    "    \n",
    "def predict_whole_seg(X, model, sess):\n",
    "    '''\n",
    "    Todo: Crop the predictions. \n",
    "    '''\n",
    "    # This shape is hardcoded based on size of subject 1's scans.\n",
    "    #segmented = np.empty((X.shape[0], 482, 395))\n",
    "    segmented = np.empty(X.shape[:3])\n",
    "    print(\"shape: \", segmented.shape)\n",
    "    num_sections = X.shape[0]\n",
    "    for i in range(num_sections):\n",
    "        pred = predict_cross_sec(X[i:i+1], model, sess)\n",
    "        # segmented[i] = crop_cross_sec(pred)\n",
    "        segmented[i] = pred\n",
    "        print(i, end=', ')\n",
    "    return segmented\n",
    "\n",
    "\n",
    "def crop_cross_sec(cross_sec):\n",
    "    '''\n",
    "    512, 512 -> 482, 395\n",
    "    npad = ((15, 15), (58, 59))  # Pads to size 512, 512\n",
    "    img = np.pad(img, pad_width=npad, mode='constant', constant_values=0)\n",
    "    \n",
    "    Hardcoded right now. Todo: remember orginal dimensions and parameterize.\n",
    "    Currently all available scans have the same dimensions, so will work hardcoded for all current scans\n",
    "    as of 06/13/18\n",
    "    '''\n",
    "    return cross_sec[15:512-15,58:512-59]\n",
    "    \n",
    "\n",
    "def convert_seg_to_nifti(seg):\n",
    "    '''\n",
    "    Hardcoded right now. Todo: generalize for any scan.\n",
    "    '''\n",
    "    base_data_dir = \"/home/jessica/Documents/hart-seg-ml/allrawnifti\"\n",
    "    original_vol = nib.load(os.path.join(base_data_dir, 'trial15_60_w1_volume_TRANS.nii'))\n",
    "    new_header = original_vol.header.copy()\n",
    "    new_nifti = nib.nifti1.Nifti1Image(seg, None, header=new_header)\n",
    "    save_dir = \"/home/jessica/Documents/hart-seg-ml/predictedsegs/u-net_v1.0/30_deg_training\"\n",
    "    save_name = \"trial15_60_w1_pred_seg.nii\"\n",
    "    nib.save(new_nifti, os.path.join(save_dir, save_name))\n",
    "    \n",
    "def convert_arr_to_nifti(arrs, orig_nii_dir, trial_name, save_dir, save_name, segmented=False):\n",
    "    '''\n",
    "    arr should be tuple of numpy arrays of shape (N, height, width). Vol first then seg.\n",
    "    '''\n",
    "    orig_nii_files = {}\n",
    "    \n",
    "    for file_name in os.listdir(orig_nifti_dir):\n",
    "        if trial_name in file_name:\n",
    "            if 'volume' in file_name:\n",
    "                orig_nii_files['volume'] = file_name\n",
    "            elif 'seg' in file_name:\n",
    "                orig_nii_files['seg'] = file_name\n",
    "    \n",
    "    print(orig_nii_files)\n",
    "    \n",
    "    orig_vol_path = os.path.join(orig_nii_dir, orig_nii_files['volume'])\n",
    "    orig_seg_path = os.path.join(orig_nii_dir, orig_nii_files['seg'])\n",
    "    \n",
    "    \n",
    "    orig_vol_nii = nib.load(orig_vol_path)\n",
    "    header = orig_vol_nii.header.copy()\n",
    "    new_vol_nii = nib.nifti1.Nifti1Image(arrs[0], None, header=header)\n",
    "    save_name = trial_name + \"_proc_filled_volume.nii\"\n",
    "    nib.save(new_vol_nii, os.path.join(save_dir, save_name))\n",
    "    \n",
    "    orig_seg_nii = nib.load(orig_seg_path)\n",
    "    header = orig_seg_nii.header.copy()\n",
    "    new_seg_nii = nib.nifti1.Nifti1Image(arrs[1], None, header=header)\n",
    "    save_name = trial_name + \"_proc_filled_seg.nii\"\n",
    "    nib.save(new_seg_nii, os.path.join(save_dir, save_name))\n",
    "    \n",
    "#     for nii in orig_nii_files:\n",
    "#         if 'volume' in nii and not segmented:\n",
    "#             nii_path = os.path.join(orig_nifti_dir, nii)\n",
    "#         elif 'seg' in nii and segmented:\n",
    "#             nii_path = os.path.join(orig_nifti_dir, nii)\n",
    "            \n",
    "#     print(nii_path)\n",
    "    \n",
    "#     orig_nii = nib.load(nii_path)\n",
    "#     header = orig_nii.header.copy()\n",
    "#     new_nii = nib.nifti1.Nifti1Image(arr, None, header=header)\n",
    "    \n",
    "#     nib.save(new_nii, os.path.join(save_dir, save_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_imgs_arr.shape)\n",
    "all_segs = predict_whole_seg(raw_imgs_arr, model, sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_segs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_seg_to_nifti(all_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape = raw_imgs_arr.shape[:3]\n",
    "convert_seg_to_nifti(raw_imgs_arr.reshape(new_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arrs = (raw_imgs_arr, seg_imgs_arr)\n",
    "\n",
    "orig_nifti_dir = \"/home/jessica/Documents/hart-seg-ml/allrawnifti\"\n",
    "curr_trial = \"trial20_90_w1\"\n",
    "save_dir = \"/home/jessica/Documents/hart-seg-ml/allrawfillednifti\"\n",
    "# save_name = \"trial8_30_fs_proc_filled_vol.nii\"\n",
    "save_name = None\n",
    "convert_arr_to_nifti(data_arrs, orig_nifti_dir, curr_trial, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
