{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.sparse\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing & Data Cleaning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sparse_csr(filename, array):\n",
    "    # note that .npz extension is added automatically\n",
    "    np.savez(filename, data=array.data, indices=array.indices,\n",
    "             indptr=array.indptr, shape=array.shape)\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    # here we need to add .npz extension manually\n",
    "    loader = np.load(filename + '.npz')\n",
    "    return csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                      shape=loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_img(img):\n",
    "    \"\"\"\n",
    "    Returns True if the image is empty\n",
    "    \"\"\"\n",
    "    return not np.count_nonzero(img)\n",
    "\n",
    "def split_filename(filename):\n",
    "    \"\"\"\n",
    "    Splits filename for a trial into 'trial10_30_w1', True if seg[label], False if vol[raw]\n",
    "    \"\"\"\n",
    "    fn_lst = filename.split('_')\n",
    "    if len(fn_lst) >= 4:\n",
    "        trial_name = \"_\".join(fn_lst[:3])\n",
    "        if 'seg' in fn_lst[3]:  \n",
    "            return trial_name, True\n",
    "        elif 'vol' in fn_lst[3]:\n",
    "            return trial_name, False\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trial20_90_w1': ['trial20_90_w1_volume_TRANS.nii',\n",
      "                   'trial20_90_w1_seg_TRANS.nii'],\n",
      " 'trial22_90_w3': ['trial22_90_w3_volume_TRANS.nii',\n",
      "                   'trial22_90_w3_seg_TRANS.nii']}\n"
     ]
    }
   ],
   "source": [
    "matched_file_dict = {}  # Dictionary of trial_key to [seg_file, vol_file]\n",
    "base_data_dir = \"/Users/saimandava/Desktop/HART/hart-seg-ml-unet/90deg\"\n",
    "for filename in os.listdir(base_data_dir):\n",
    "    trial_key, is_seg = split_filename(filename)\n",
    "    if trial_key is not None:\n",
    "        if trial_key not in matched_file_dict:\n",
    "            matched_file_dict[trial_key] = [None, None]\n",
    "        if is_seg:\n",
    "            matched_file_dict[trial_key][1] = filename\n",
    "        else:\n",
    "            matched_file_dict[trial_key][0] = filename\n",
    "        \n",
    "from pprint import pprint\n",
    "pprint(matched_file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1188, 482, 395)\n"
     ]
    }
   ],
   "source": [
    "example_segmentation = os.path.join(base_data_dir, 'trial20_90_w1_seg_TRANS.nii')\n",
    "example_rawscan = os.path.join(base_data_dir, 'trial20_90_w1_volume_TRANS.nii')\n",
    "\n",
    "\n",
    "scan_voxel = nib.load(example_segmentation)\n",
    "# struct_arr = scan_voxel.get_data()\n",
    "# print(struct_arr.shape)\n",
    "# class_labels = np.unique(struct_arr)\n",
    "\n",
    "base_data_dir = \"/Users/saimandava/Desktop/HART/hart-seg-ml-unet/90deg\"\n",
    "# for filename in os.listdir(base_data_dir):\n",
    "#     if 'seg' in filename:\n",
    "#         scan_voxel = nib.load(os.path.join(base_data_dir, filename))\n",
    "#         struct_arr = scan_voxel.get_data()\n",
    "#         print(struct_arr.shape)\n",
    "#         class_labels = np.unique(struct_arr)\n",
    "#         print(class_labels)\n",
    "        \n",
    "struct_arr = scan_voxel.get_data()\n",
    "print(struct_arr.shape)\n",
    "class_labels = np.unique(struct_arr)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "unique_classes = [  0.,   7.,   8.,   9.,  45.,  51.,  52.,  53.,  68.]\n",
    "def one_hot_encode(img, classes):\n",
    "    h, w = img.shape  # 482, 395\n",
    "    one_hot_encoder = preprocessing.OneHotEncoder()\n",
    "    one_hot_encoder.fit(np.flatten(img), unique_classes)\n",
    "    \n",
    "one_hot_encoder = preprocessing.OneHotEncoder(struct_arr.flatten())\n",
    "\n",
    "# x = 400\n",
    "# sample_img = struct_arr[x:x+1]\n",
    "# one_hot_encode(sample_img)\n",
    "\n",
    "        \n",
    "# from scipy.sparse import coo_matrix\n",
    "# def onehot_sparse(a):\n",
    "#     N = a.size\n",
    "#     L = a.max()+1\n",
    "#     data = np.ones(N,dtype=int)\n",
    "#     return coo_matrix((data,(np.arange(N),a.ravel())), shape=(N,L))\n",
    "\n",
    "# for i in range(60):\n",
    "#     img = scan_voxel[i]\n",
    "#     print(img.shape)\n",
    "#     print(img)\n",
    "\n",
    "# plotting.plot_stat_map(img)\n",
    "# plotting.show()\n",
    "\n",
    "# data1 = scan_voxel.get_data()\n",
    "# x = 400\n",
    "# for i in data1[x-1:x]:\n",
    "#     print(i.shape)\n",
    "#     print(empty_img(i))\n",
    "# #     print(i[200,:])\n",
    "#     plt.imshow(i)\n",
    "#     plt.show()\n",
    "# #     print(i.shape)\n",
    "# #     plotting.plot_stat_map(i)\n",
    "# #     plotting.show()\n",
    "# im = data1[x-1:x][0]\n",
    "# plt.imshow(im)\n",
    "# plt.show()\n",
    "# print(im.shape)\n",
    "\n",
    "# def bounding_box(img):\n",
    "#     rows = np.any(img, axis=1)\n",
    "#     cols = np.any(img, axis=0)\n",
    "#     rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "#     cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "#     box = im[rmin : rmax, cmin : cmax]\n",
    "#     return box\n",
    "# #     return rmin, rmax, cmin, cmax\n",
    "# box = bounding_box(im)\n",
    "# print(box.shape)\n",
    "# plt.imshow(box)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_voxel = nib.load(example_segmentation)\n",
    "struct_arr = scan_voxel.get_data()\n",
    "n, h, w = struct_arr.shape\n",
    "class_labels = list(np.unique(struct_arr))\n",
    "flattened_images = struct_arr.flatten().reshape((n,h*w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 7.0, 8.0, 9.0, 45.0, 51.0, 52.0, 53.0, 68.0]\n",
      "[  0.   7.  45.  52.  53.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 4, 6, 7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(class_labels)\n",
    "\n",
    "i = struct_arr[400]\n",
    "print(np.unique(i))\n",
    "plt.imshow(i)\n",
    "plt.show()\n",
    "\n",
    "# Custom one hot image encoding function\n",
    "encoded = np.array([list(map(class_labels.index, flattened_images[i])) for i in range(400, 402)])\n",
    "ei = encoded[0].reshape(h, w)\n",
    "plt.imshow(i)\n",
    "plt.show()\n",
    "\n",
    "np.unique(encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1188, 482, 395)\n",
      "20.78929114341736\n"
     ]
    }
   ],
   "source": [
    "example_segmentation = os.path.join(base_data_dir, 'trial20_90_w1_seg_TRANS.nii')\n",
    "scan_voxel = nib.load(example_segmentation)\n",
    "print(scan_voxel.shape)\n",
    "data1 = scan_voxel.get_data()\n",
    "x = 400\n",
    "im = data1[x-1:x][0]\n",
    "\n",
    "def fill(image, threshold_dist=10):\n",
    "    rows, cols = len(image), len(image[0])\n",
    "    for u in range(rows):  # Iterate through rows\n",
    "        for v in range(cols):  # Iterate through cols\n",
    "            ltr_color, gtr_color, ltc_color, gtc_color = False, False, False, False\n",
    "            for ltr in range(u, max(0, u-threshold_dist), -1):\n",
    "                if image[ltr, v] != 0: \n",
    "                    ltr_color = image[ltr, v]\n",
    "                    break\n",
    "            for gtr in range(u, min(rows, u+threshold_dist)):\n",
    "                if image[gtr, v] != 0: \n",
    "                    gtr_color = image[gtr, v]\n",
    "                    break\n",
    "            for ltc in range(v, max(0, v-threshold_dist), -1):\n",
    "                if image[u, ltc] != 0: \n",
    "                    ltc_color = image[u, ltc]\n",
    "                    break\n",
    "            for gtc in range(v, min(cols, v+threshold_dist)):\n",
    "                if image[u, gtc] != 0: \n",
    "                    gtc_color = image[u, gtc]\n",
    "                    break\n",
    "            if np.all([ltr_color, gtr_color, ltc_color, gtc_color]):\n",
    "                if len(set([ltr_color, gtr_color, ltc_color, gtc_color])) == 1:\n",
    "                    image[u, v] = ltr_color\n",
    "    return image\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "plt.imshow(fill(im))\n",
    "plt.show()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img_data_dir = \"/Users/kireet/ucb/HART Research/Muscle Segmentation/cleaned_sparse_images\"\n",
    "\n",
    "def build_sparse_image_dataset(trial_key, raw_nii, label_nii):\n",
    "    raw_nii_file = os.path.join(base_data_dir, raw_nii)\n",
    "    label_nii_file = os.path.join(base_data_dir, label_nii)\n",
    "    raw_voxel = nib.load(raw_nii_file).get_data()\n",
    "    label_voxel = nib.load(label_nii_file).get_data()\n",
    "    \n",
    "    raw_clean_voxel, labeled_clean_voxel = None, None\n",
    "    for i in range(raw_voxel.shape[0]):  # shape is (1188, 482, 395)\n",
    "        if empty_img(raw_voxel[i]) or empty_img(label_voxel[i]):\n",
    "            continue\n",
    "            \n",
    "        raw_img = raw_voxel[i]\n",
    "        labeled_img = fill(label_voxel[i])  # Grid fill the labeled image\n",
    "        \n",
    "        raw_sparse_mat = scipy.sparse.csr_matrix(raw_img)  # convert to sparse matrix\n",
    "        labeled_sparse_mat = scipy.sparse.csr_matrix(labeled_img)\n",
    "        \n",
    "        if raw_clean_voxel is not None:\n",
    "            scipy.sparse.hstack([raw_clean_voxel, raw_sparse_mat])\n",
    "        else:\n",
    "            raw_clean_voxel = raw_sparse_mat\n",
    "        if labeled_clean_voxel is not None:\n",
    "            scipy.sparse.hstack([labeled_clean_voxel, labeled_sparse_mat])\n",
    "        else:\n",
    "            labeled_clean_voxel = labeled_sparse_mat\n",
    "            \n",
    "    save_sparse_csr(os.path.join(base_img_data_dir, trial_key + '_raw'), raw_clean_voxel)  # Save the sparse matrices\n",
    "    save_sparse_csr(os.path.join(base_img_data_dir, trial_key + '_labeled'), labeled_clean_voxel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matched_file_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8922a98aa5fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Runs the cleaning image voxel dataset -> creates cleaned 3D voxels OR can convert to 2D images with some mods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_lst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatched_file_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbuild_sparse_image_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Remove break to create images for all scans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matched_file_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Runs the cleaning image voxel dataset -> creates cleaned 3D voxels OR can convert to 2D images with some mods\n",
    "for tk, scan_lst in list(matched_file_dict.items()):\n",
    "    build_sparse_image_dataset(tk, scan_lst[0], scan_lst[1])\n",
    "    break  # Remove break to create images for all scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_img_data_dir = \"/Users/kireet/ucb/HART Research/Muscle Segmentation/cleaned_images\"\n",
    "\n",
    "def build_image_dataset(trial_key, raw_nii, label_nii):\n",
    "    raw_nii_file = os.path.join(base_data_dir, raw_nii)\n",
    "    label_nii_file = os.path.join(base_data_dir, label_nii)\n",
    "    raw_voxel = nib.load(raw_nii_file).get_data()\n",
    "    label_voxel = nib.load(label_nii_file).get_data()\n",
    "    \n",
    "    counter = 0\n",
    "    trial_img_dir = os.path.join(base_img_data_dir, trial_key)\n",
    "    if not os.path.exists(trial_img_dir):\n",
    "        os.makedirs(trial_img_dir)\n",
    "    raw_clean_voxel, labeled_clean_voxel = None, None\n",
    "    for i in range(400, 402):  #range(raw_voxel.shape[0]):  # shape is (1188, 482, 395)\n",
    "        if empty_img(raw_voxel[i]) or empty_img(label_voxel[i]):\n",
    "            continue\n",
    "            \n",
    "        raw_img = raw_voxel[i]\n",
    "        labeled_img = fill(label_voxel[i])  # Grid fill the labeled image\n",
    "        \n",
    "        scipy.misc.imsave(os.path.join(trial_img_dir, str(counter) + '_raw.jpg'), raw_img)\n",
    "        scipy.misc.imsave(os.path.join(trial_img_dir, str(counter) + '_label.jpg'), labeled_img)\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        if counter > 60:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the cleaning image voxel dataset -> creates cleaned 2D jpegs\n",
    "for tk, scan_lst in list(matched_file_dict.items()):\n",
    "    build_image_dataset(tk, scan_lst[0], scan_lst[1])\n",
    "    break  # Remove break to create images for all scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Determine if 512, 512 Data padding with zeros is necessary\n",
    "\n",
    "x_train, y_train = [], []\n",
    "x_val, y_val = [], []\n",
    "x_test, y_test = [], []\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    filename = filenames[i]\n",
    "    study = '_'.join(filename.split('_')[:4])\n",
    "    if study in train_lst: \n",
    "        x_train.append(images[i])\n",
    "        y_train.append(segmentations[i])\n",
    "    else:\n",
    "        x_test.append(images[i])\n",
    "        y_test.append(segmentations[i])\n",
    "                \n",
    "x_train = np.array(x_train).reshape((len(x_train),im_size,im_size,1))\n",
    "x_test = np.array(x_test).reshape((len(x_test),im_size,im_size,1))\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Tensorflow or Keras U-Net here\n",
    "\n",
    "h, w = 482, 395\n",
    "\n",
    "class Unet(object):        \n",
    "    def __init__(self, mean, weight_decay, learning_rate, label_dim = 8, dropout = 0.9):\n",
    "        self.x_train = tf.placeholder(tf.float32, [None, h, w, 1])\n",
    "        self.y_train = tf.placeholder(tf.float32, [None, h, w, 7])\n",
    "        self.x_test = tf.placeholder(tf.float32, [None, h, w, 1])\n",
    "        self.y_test = tf.placeholder(tf.float32, [None, h, w, 7])\n",
    "        \n",
    "        self.label_dim = label_dim\n",
    "        self.weight_decay = weight_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.output = self.unet(self.x_train, mean, keep_prob=self.dropout)\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.output, labels = self.y_train))\n",
    "        self.opt = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "        \n",
    "        self.pred = self.unet(self.x_test, mean, reuse = True, keep_prob = 1.0)\n",
    "        self.loss_summary = tf.summary.scalar('loss', self.loss)\n",
    "    \n",
    "    # Gradient Descent on mini-batch\n",
    "    def fit_batch(self, sess, x_train, y_train):\n",
    "        _, loss, loss_summary = sess.run((self.opt, self.loss, self.loss_summary), feed_dict={self.x_train: x_train, self.y_train: y_train})\n",
    "        return loss, loss_summary\n",
    "    \n",
    "    def predict(self, sess, x):\n",
    "        prediction = sess.run((self.pred), feed_dict={self.x_test: x})\n",
    "        return prediction\n",
    "\n",
    "    \n",
    "    def unet(self, input, mean, keep_prob = 0.9, reuse = None):\n",
    "        with tf.variable_scope('vgg', reuse=reuse):\n",
    "            input = input - mean\n",
    "            pool_ = lambda x: nn.max_pool(x, 2, 2)\n",
    "            conv_ = lambda x, output_depth, name, padding = 'SAME', relu = True, filter_size = 3: nn.conv(x, filter_size, output_depth, 1, self.weight_decay, \n",
    "                                                                                                           name=name, padding=padding, relu=relu)\n",
    "            deconv_ = lambda x, output_depth, name: nn.deconv(x, 2, output_depth, 2, self.weight_decay, name=name)\n",
    "            \n",
    "            conv_1_1 = conv_(input, 64, 'conv1_1')\n",
    "            conv_1_2 = conv_(conv_1_1, 64, 'conv1_2')\n",
    "\n",
    "            pool_1 = pool_(conv_1_2)\n",
    "\n",
    "            conv_2_1 = conv_(pool_1, 128, 'conv2_1')\n",
    "            conv_2_2 = conv_(conv_2_1, 128, 'conv2_2')\n",
    "\n",
    "            pool_2 = pool_(conv_2_2)\n",
    "\n",
    "            conv_3_1 = conv_(pool_2, 256, 'conv3_1')\n",
    "            conv_3_2 = conv_(conv_3_1, 256, 'conv3_2')\n",
    "\n",
    "            pool_3 = pool_(conv_3_2)\n",
    "\n",
    "            conv_4_1 = conv_(pool_3, 512, 'conv4_1')\n",
    "            conv_4_2 = conv_(conv_4_1, 512, 'conv4_2')\n",
    "\n",
    "            pool_4 = pool_(conv_4_2)\n",
    "\n",
    "            conv_5_1 = conv_(pool_4, 1024, 'conv5_1')\n",
    "            conv_5_2 = conv_(conv_5_1, 1024, 'conv5_2')\n",
    "            \n",
    "            pool_5 = pool_(conv_5_2)\n",
    "            \n",
    "            conv_6_1 = tf.nn.dropout(conv_(pool_5, 2048, 'conv6_1'), keep_prob)\n",
    "            conv_6_2 = tf.nn.dropout(conv_(conv_6_1, 2048, 'conv6_2'), keep_prob)\n",
    "            \n",
    "            up_7 = tf.concat([deconv_(conv_6_2, 1024, 'up7'), conv_5_2], 3)\n",
    "            \n",
    "            conv_7_1 = conv_(up_7, 1024, 'conv7_1')\n",
    "            conv_7_2 = conv_(conv_7_1, 1024, 'conv7_2')\n",
    "\n",
    "            up_8 = tf.concat([deconv_(conv_7_2, 512, 'up8'), conv_4_2], 3)\n",
    "            \n",
    "            conv_8_1 = conv_(up_8, 512, 'conv8_1')\n",
    "            conv_8_2 = conv_(conv_8_1, 512, 'conv8_2')\n",
    "\n",
    "            up_9 = tf.concat([deconv_(conv_8_2, 256, 'up9'), conv_3_2], 3)\n",
    "            \n",
    "            conv_9_1 = conv_(up_9, 256, 'conv9_1')\n",
    "            conv_9_2 = conv_(conv_9_1, 256, 'conv9_2')\n",
    "\n",
    "            up_10 = tf.concat([deconv_(conv_9_2, 128, 'up10'), conv_2_2], 3)\n",
    "            \n",
    "            conv_10_1 = conv_(up_10, 128, 'conv10_1')\n",
    "            conv_10_2 = conv_(conv_10_1, 128, 'conv10_2')\n",
    "\n",
    "            up_11 = tf.concat([deconv_(conv_10_2, 64, 'up11'), conv_1_2], 3)\n",
    "            \n",
    "            conv_11_1 = conv_(up_11, 64, 'conv11_1')\n",
    "            conv_11_2 = conv_(conv_11_1, 64, 'conv11_2')\n",
    "            \n",
    "            conv_12 = conv_(conv_11_2, 7, 'conv12_2', filter_size = 1, relu = False)\n",
    "            return conv_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "mean = 24\n",
    "weight_decay = 1e-6\n",
    "learning_rate = 1e-4\n",
    "label_dim = 8\n",
    "maxout = False\n",
    "\n",
    "# Create TF graph and initialize variables\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "model = Unet(mean, weight_decay, learning_rate, label_dim , dropout = 0.5)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restore old model\n",
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess, '/media/deoraid03/jeff/models/a4c_experiments/deep_256_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Model\n",
    "nn.train(sess, model, x_train, y_train, x_test, y_test, epochs = 20, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IOU Accuracies for each label\n",
    "nn.validate(sess, model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "# saver = tf.train.Saver()\n",
    "# saver.save(sess, '/media/deoraid03/jeff/models/a4c_experiments/deep_256_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
