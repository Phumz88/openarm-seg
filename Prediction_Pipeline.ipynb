{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14723778393412094249\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(\"imported\")\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "sys.path.append('src/')\n",
    "import nn\n",
    "import process_data\n",
    "import nibabel as nib\n",
    "from math import floor, ceil\n",
    "# import cv2\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy.sparse\n",
    "from scipy.misc import imrotate, imresize\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage import rotate\n",
    "from skimage import exposure\n",
    "from skimage.io import imread, imsave\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "print(local_device_protos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(L, class_labels):\n",
    "    \"\"\"\n",
    "    2D array (image) of segmentation labels -> .npy\n",
    "    # One Hot Encode the label 2d array -> .npy files with dim (h, w, len(class_labels))\n",
    "    # num classes will be 8? but currently dynamically allocated based on num colors in all scans.\n",
    "    \"\"\"\n",
    "    h, w = L.shape  # Should be 482, 395 (unless resized)\n",
    "    try:\n",
    "        encoded = np.array([list(map(class_labels.index, L.flatten()))])\n",
    "\n",
    "        L = encoded.reshape(h, w)\n",
    "\n",
    "        Lhot = np.zeros((L.shape[0], L.shape[1], len(class_labels)))\n",
    "        for i in range(L.shape[0]):\n",
    "            for j in range(L.shape[1]):\n",
    "                Lhot[i,j,L[i,j]] = 1\n",
    "        return Lhot  # Should be shape (482, 395, 9)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "def uncode_one_hot(npy_file):\n",
    "    \"\"\"\n",
    "    .npy file -> JPEG\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "#         if image.ndim == 2:\n",
    "#             plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()\n",
    "    \n",
    "def load_sparse_csr(filename):\n",
    "    # Sparse matrix reading function to read our raw .npz files\n",
    "    assert filename.endswith('.npz')\n",
    "    loader = np.load(filename)  # filename must end with .npz\n",
    "    return scipy.sparse.csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                      shape=loader['shape'])\n",
    "\n",
    "def get_raw_pixel_classes(trial_name, raw_nifti_dir):\n",
    "    trial_segmentation = None\n",
    "    \n",
    "    for raw_nii in os.listdir(raw_nii_dir):\n",
    "        if raw_nii.startswith(trial_name) and raw_nii.endswith(\".nii\"):\n",
    "            if \"seg\" in raw_nii:\n",
    "                trial_segmentation = os.path.join(raw_nii_dir, raw_nii)\n",
    "                break\n",
    "    \n",
    "    scan_voxel = nib.load(trial_segmentation)\n",
    "    struct_arr = scan_voxel.get_data()\n",
    "    class_labels = sorted(list(np.unique(struct_arr)))\n",
    "    return class_labels\n",
    "    \n",
    "def check_one_hot(encoded_img):\n",
    "    print(encoded_img.shape)\n",
    "    return np.all(np.sum(encoded_img, axis=2) == 1.)\n",
    "\n",
    "def batch_img_resize(images, h = 256, w = 256):\n",
    "    images_resized = np.zeros([0, newHeight, newWidth], dtype=np.uint8)\n",
    "    for image in range(images.shape[0]):\n",
    "        temp = imresize(images[image], [h, w], 'nearest')\n",
    "        images_resized = np.append(images_resized, np.expand_dims(temp, axis=0), axis=0)\n",
    "    return images_resized\n",
    "\n",
    "def crop_cross_sec(cross_sec, height, width):\n",
    "    orig_height, orig_width = cross_sec.shape\n",
    "    height_remove = (orig_height - height) / 2\n",
    "    width_remove = (orig_width - width) / 2\n",
    "    ht_idx_1 = floor(height_remove)\n",
    "    ht_idx_2 = ceil(height_remove)\n",
    "    wd_idx_1 = floor(width_remove)\n",
    "    wd_idx_2 = ceil(width_remove)\n",
    "    \n",
    "    cropped = cross_sec[ht_idx_1:orig_height-ht_idx_2, wd_idx_1:orig_width-wd_idx_2]\n",
    "    \n",
    "    return cropped\n",
    "\n",
    "def pad_image(orig_img, height, width):    \n",
    "    orig_height, orig_width = orig_img.shape\n",
    "    \n",
    "    height_pad = (height - orig_height) / 2\n",
    "    width_pad = (width - orig_width) / 2\n",
    "    \n",
    "    height_top_pad = floor(height_pad)\n",
    "    height_bot_pad =  ceil(height_pad)\n",
    "    width_left_pad = floor(width_pad)\n",
    "    width_right_pad = ceil(width_pad)\n",
    "    \n",
    "    pad_dims = ((height_top_pad, height_bot_pad), (width_left_pad, width_right_pad))\n",
    "    padded_img = np.pad(orig_img, pad_width=pad_dims, mode='constant', constant_values=0)\n",
    "    \n",
    "    return padded_img\n",
    "\n",
    "def load_data(processed_data_dir, raw_data_dir, height=512, width=512, use_default_classes=True):\n",
    "    \"\"\"\n",
    "    Load both the raw, unlabeled scan data as well as corresponding labeled segmentation data.\n",
    "    Can draw from an arbitrary number of scan/segmentation pairs. All raw data ends up in the\n",
    "    same array, all segmentation data ends up in the same array.\n",
    "    \n",
    "    Args:\n",
    "        processed_data_dir (str): Path to directory containing separate folders for the preprocessed\n",
    "            data, where each folder contains all .npz and .png files for one scan. Name expected\n",
    "            to resemble, e.g. \"trial8_30_fs\".\n",
    "        raw_data_dir (str): Path to directory containing original .nii files of each scan being used,\n",
    "            each should not be in sub-folder. Should include both unsegmented and segmented .nii.\n",
    "        height (int): Height in pixels to which scan cross sections get resized.\n",
    "        width (int): Width in pixels to which scan cross sections get resized.\n",
    "        use_default_classes (bool): Flag indicating whether each scan being used should use default\n",
    "            set of classes. If false, classes will be individually determined for each scan.\n",
    "            \n",
    "    Returns:\n",
    "        tuple: Tuple of numpy arrays where the first array contains the raw data and is of shape\n",
    "            (N, height, width), where N is total number of cross sections from all scans; the second\n",
    "            contains the segmented data and is of shape (N, 512, 512, C) where C is the number of\n",
    "            pixel classes. By default C is 9. Class dimension is one-hot-encoded. \n",
    "    \"\"\"\n",
    "    default_raw_pixel_classes = [0, 7, 8, 9, 45, 51, 52, 53, 68]\n",
    "    raw_images = []\n",
    "    segmentations = []\n",
    "    all_raw_pixel_classes = {}\n",
    "    \n",
    "    for folder in os.listdir(processed_data_dir):\n",
    "        if not folder.startswith('.'):\n",
    "            trial_folder_path = os.path.join(processed_data_dir, folder)\n",
    "            print(\"====\")\n",
    "            print(trial_folder_path)\n",
    "            print(\"====\")\n",
    "\n",
    "            trial_files = []\n",
    "\n",
    "            for item in os.listdir(trial_folder_path):\n",
    "                item_path = os.path.join(trial_folder_path, item)\n",
    "                if os.path.isfile(item_path) and not item.startswith('.'):\n",
    "                    trial_files.append(item)\n",
    "\n",
    "            trial_files = sorted(trial_files)\n",
    "\n",
    "            \n",
    "            if use_default_classes:\n",
    "                all_raw_pixel_classes[folder] = default_raw_pixel_classes\n",
    "            else:\n",
    "                all_raw_pixel_classes[folder] = get_raw_pixel_classes(folder, raw_data_dir)\n",
    "\n",
    "            for file in trial_files:\n",
    "                print(file, end=\", \")\n",
    "                if 'label' in file:\n",
    "                    img = imread(os.path.join(trial_folder_path, file), flatten=True)\n",
    "                else:\n",
    "                    img = load_sparse_csr(os.path.join(trial_folder_path, file)).toarray()            \n",
    "\n",
    "                img = pad_image(img, height, width)\n",
    "                if 'raw' in file:\n",
    "                    raw_images.append(img)\n",
    "                elif 'label' in file:\n",
    "                    encoded_img = one_hot_encode(img, all_raw_pixel_classes[folder])\n",
    "                    segmentations.append(encoded_img)\n",
    "        print(\"\")\n",
    "    \n",
    "    raw_images_arr = np.array(raw_images)\n",
    "    segmentations_arr = np.array(segmentations)\n",
    "    return raw_images_arr, segmentations_arr\n",
    "\n",
    "\n",
    "def convert_seg_to_nifti(seg):\n",
    "    '''\n",
    "    Hardcoded right now. Todo: generalize for any scan.\n",
    "    '''\n",
    "    base_data_dir = \"/home/jessica/Documents/hart-seg-ml/allrawnifti\"\n",
    "    original_vol = nib.load(os.path.join(base_data_dir, 'trial15_60_w1_volume_TRANS.nii'))\n",
    "    new_header = original_vol.header.copy()\n",
    "    new_nifti = nib.nifti1.Nifti1Image(seg, None, header=new_header)\n",
    "    nib.save(new_nifti, '/home/jessica/Documents/hart-seg-ml/predictedsegs/trial15_60_w1_first/trial15_60_w1_first_pred_seg.nii')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cross_sec(x, model, sess):\n",
    "    prediction = model.predict(sess, x)\n",
    "    pred_classes = np.argmax(prediction[0], axis=2)\n",
    "    return pred_classes\n",
    "\n",
    "    \n",
    "def predict_whole_seg(X, model, sess):\n",
    "    '''\n",
    "    Todo: Crop the predictions. \n",
    "    '''\n",
    "    segmented = np.empty(X.shape[:3])\n",
    "    num_sections = X.shape[0]\n",
    "    for i in range(num_sections):\n",
    "        pred = predict_cross_sec(X[i:i+1], model, sess)\n",
    "        segmented[i] = pred\n",
    "        print(i, end=', ')\n",
    "    return segmented\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====\n",
      "/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/trial12_30_w3\n",
      "====\n",
      "0_label.png, 0_raw.npz, 10_label.png, 10_raw.npz, 11_label.png, 11_raw.npz, 12_label.png, 12_raw.npz, 13_label.png, 13_raw.npz, 14_label.png, 14_raw.npz, 15_label.png, 15_raw.npz, 16_label.png, 16_raw.npz, 17_label.png, 17_raw.npz, 18_label.png, 18_raw.npz, 19_label.png, 19_raw.npz, 1_label.png, 1_raw.npz, 20_label.png, 20_raw.npz, 21_label.png, 21_raw.npz, 22_label.png, 22_raw.npz, 23_label.png, 23_raw.npz, 24_label.png, 24_raw.npz, 25_label.png, 25_raw.npz, 26_label.png, 26_raw.npz, 27_label.png, 27_raw.npz, 28_label.png, 28_raw.npz, 29_label.png, 29_raw.npz, 2_label.png, 2_raw.npz, 30_label.png, 30_raw.npz, 3_label.png, 3_raw.npz, 4_label.png, 4_raw.npz, 5_label.png, 5_raw.npz, 6_label.png, 6_raw.npz, 7_label.png, 7_raw.npz, 8_label.png, 8_raw.npz, 9_label.png, 9_raw.npz, \n",
      "====\n",
      "/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/trial15_60_w1\n",
      "====\n",
      "0_label.png, 0_raw.npz, 10_label.png, 10_raw.npz, 11_label.png, 11_raw.npz, 12_label.png, 12_raw.npz, 13_label.png, 13_raw.npz, 14_label.png, 14_raw.npz, 15_label.png, 15_raw.npz, 16_label.png, 16_raw.npz, 17_label.png, 17_raw.npz, 18_label.png, 18_raw.npz, 19_label.png, 19_raw.npz, 1_label.png, 1_raw.npz, 20_label.png, 20_raw.npz, 21_label.png, 21_raw.npz, 22_label.png, 22_raw.npz, 23_label.png, 23_raw.npz, 24_label.png, 24_raw.npz, 25_label.png, 25_raw.npz, 26_label.png, 26_raw.npz, 27_label.png, 27_raw.npz, 28_label.png, 28_raw.npz, 29_label.png, 29_raw.npz, 2_label.png, 2_raw.npz, 30_label.png, 30_raw.npz, 3_label.png, 3_raw.npz, 4_label.png, 4_raw.npz, 5_label.png, 5_raw.npz, 6_label.png, 6_raw.npz, 7_label.png, 7_raw.npz, 8_label.png, 8_raw.npz, 9_label.png, 9_raw.npz, \n"
     ]
    }
   ],
   "source": [
    "raw_nii_dir = \"/Users/nozik/Documents/HARTresearch/allrawnifti\"\n",
    "preproc_data_dir = \"/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test\"\n",
    "\n",
    "raw_data, seg_data = load_data(preproc_data_dir, raw_nii_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 512, 512)\n",
      "(62, 512, 512, 9)\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.shape)\n",
    "print(seg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "(482, 395)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1177ba400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_img = raw_data[0]\n",
    "print(example_img.shape)\n",
    "cropped_example = crop_cross_sec(example_img, 482, 395)\n",
    "print(cropped_example.shape)\n",
    "\n",
    "#plt.imshow(example_img)\n",
    "plt.imshow(cropped_example)\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Separate out image padding from the load data method so that data can be loaded in original form, preserving original dimensions for resizing post-prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
