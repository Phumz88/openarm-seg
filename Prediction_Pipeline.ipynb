{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11934193545933816460\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(\"imported\")\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "sys.path.append('src/')\n",
    "import nn\n",
    "import process_data\n",
    "import nibabel as nib\n",
    "from math import floor, ceil\n",
    "# import cv2\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy.sparse\n",
    "from scipy.misc import imrotate, imresize\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage import rotate\n",
    "from skimage import exposure\n",
    "from skimage.io import imread, imsave\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "print(local_device_protos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(L, class_labels):\n",
    "    \"\"\"\n",
    "    2D array (image) of segmentation labels -> .npy\n",
    "    # One Hot Encode the label 2d array -> .npy files with dim (h, w, len(class_labels))\n",
    "    # num classes will be 8? but currently dynamically allocated based on num colors in all scans.\n",
    "    \"\"\"\n",
    "    h, w = L.shape  # Should be 482, 395 (unless resized)\n",
    "    try:\n",
    "        encoded = np.array([list(map(class_labels.index, L.flatten()))])\n",
    "\n",
    "        L = encoded.reshape(h, w)\n",
    "\n",
    "        Lhot = np.zeros((L.shape[0], L.shape[1], len(class_labels)))\n",
    "        for i in range(L.shape[0]):\n",
    "            for j in range(L.shape[1]):\n",
    "                Lhot[i,j,L[i,j]] = 1\n",
    "        return Lhot  # Should be shape (482, 395, 9)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def uncode_one_hot(npy_file):\n",
    "    \"\"\"\n",
    "    .npy file -> JPEG\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "#         if image.ndim == 2:\n",
    "#             plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()\n",
    "    \n",
    "def load_sparse_csr(filename):\n",
    "    # Sparse matrix reading function to read our raw .npz files\n",
    "    assert filename.endswith('.npz')\n",
    "    loader = np.load(filename)  # filename must end with .npz\n",
    "    return scipy.sparse.csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                      shape=loader['shape'])\n",
    "\n",
    "def get_raw_pixel_classes(trial_name, raw_nifti_dir):\n",
    "    trial_segmentation = None\n",
    "    \n",
    "    for raw_nii in os.listdir(raw_nii_dir):\n",
    "        if raw_nii.startswith(trial_name) and raw_nii.endswith(\".nii\"):\n",
    "            if \"seg\" in raw_nii:\n",
    "                trial_segmentation = os.path.join(raw_nii_dir, raw_nii)\n",
    "                break\n",
    "    \n",
    "    scan_voxel = nib.load(trial_segmentation)\n",
    "    struct_arr = scan_voxel.get_data()\n",
    "    class_labels = sorted(list(np.unique(struct_arr)))\n",
    "    return class_labels\n",
    "    \n",
    "def check_one_hot(encoded_img):\n",
    "    print(encoded_img.shape)\n",
    "    return np.all(np.sum(encoded_img, axis=2) == 1.)\n",
    "\n",
    "def batch_img_resize(images, h = 256, w = 256):\n",
    "    images_resized = np.zeros([0, newHeight, newWidth], dtype=np.uint8)\n",
    "    for image in range(images.shape[0]):\n",
    "        temp = imresize(images[image], [h, w], 'nearest')\n",
    "        images_resized = np.append(images_resized, np.expand_dims(temp, axis=0), axis=0)\n",
    "    return images_resized\n",
    "\n",
    "def crop_cross_sec(cross_sec, height, width):\n",
    "    orig_height, orig_width = cross_sec.shape\n",
    "    height_remove = (orig_height - height) / 2\n",
    "    width_remove = (orig_width - width) / 2\n",
    "    ht_idx_1 = floor(height_remove)\n",
    "    ht_idx_2 = ceil(height_remove)\n",
    "    wd_idx_1 = floor(width_remove)\n",
    "    wd_idx_2 = ceil(width_remove)\n",
    "    \n",
    "    cropped = cross_sec[ht_idx_1:orig_height-ht_idx_2, wd_idx_1:orig_width-wd_idx_2]\n",
    "    \n",
    "    return cropped\n",
    "\n",
    "def pad_image(orig_img, height, width):    \n",
    "    orig_height, orig_width = orig_img.shape\n",
    "    \n",
    "    height_pad = (height - orig_height) / 2\n",
    "    width_pad = (width - orig_width) / 2\n",
    "    \n",
    "    height_top_pad = floor(height_pad)\n",
    "    height_bot_pad =  ceil(height_pad)\n",
    "    width_left_pad = floor(width_pad)\n",
    "    width_right_pad = ceil(width_pad)\n",
    "    \n",
    "    pad_dims = ((height_top_pad, height_bot_pad), (width_left_pad, width_right_pad))\n",
    "    padded_img = np.pad(orig_img, pad_width=pad_dims, mode='constant', constant_values=0)\n",
    "    \n",
    "    return padded_img\n",
    "\n",
    "def pad_processed_data():\n",
    "    pass\n",
    "    \n",
    "\n",
    "def load_all_data(processed_data_dir=None, height=512, width=512):\n",
    "    \"\"\"\n",
    "    Load both the processed, unlabeled data as well as corresponding labeled segmentation data (if it\n",
    "    exists) of all scans in a directory. Can draw from an arbitrary number of scan/segmentation pairs. \n",
    "    All raw data ends up in the same array, all segmentation data ends up in the same array.\n",
    "    \n",
    "    Args:\n",
    "        processed_data_dir (str): Path to directory containing separate folders for the preprocessed\n",
    "            data, where each folder contains all .npz and .png files for one scan. Sub-folder names\n",
    "            expected to resemble e.g. \"trial8_30_fs\".\n",
    "        height (int): Height in pixels to which scan cross sections get resized.\n",
    "        width (int): Width in pixels to which scan cross sections get resized.\n",
    "            \n",
    "    Returns:\n",
    "        tuple: Tuple of lists of numpy arrays where the first list contains the raw data, is of length \n",
    "            N (total number of cross sections from all scans), and each element is a numpy array of shape\n",
    "            (height, width). The second list contains the segmented data and is of length N and\n",
    "            contains numpy arrays of shape (height, width, C) where C is the number of\n",
    "            pixel classes. By default C is 9. Class dimension is one-hot-encoded.\n",
    "    \"\"\"\n",
    "    raw_images = []\n",
    "    segmentations = []    \n",
    "    scan_paths = []\n",
    "    \n",
    "    for folder in os.listdir(processed_data_dir):\n",
    "        if not folder.startswith('.') and 'trial' in folder.lower():\n",
    "            scan_folder_path = os.path.join(processed_data_dir, folder)\n",
    "            scan_paths.append(scan_folder_path)\n",
    "    \n",
    "    print(scan_paths)\n",
    "    \n",
    "    for scan_path in scan_paths:\n",
    "        scan_data_raw, scan_data_labels = load_data(scan_path, height, width)\n",
    "        raw_images.extend(scan_data_raw)\n",
    "        segmentations.extend(scan_data_labels)\n",
    "    \n",
    "    return raw_images, segmentations\n",
    "\n",
    "def load_data(processed_data_dir=None, height=512, width=512):\n",
    "    \"\"\"\n",
    "    Load both the processed, unlabeled data as well as corresponding labeled segmentation data (if it\n",
    "    exists) of a single scan. \n",
    "    \n",
    "    Args:\n",
    "        processed_data_dir (str): Path to directory containing the .npz and .png files for a single scan.\n",
    "            Name of this directory does not matter. Directory should only contain the relevant processed\n",
    "            scan data, not any other files.\n",
    "        height (int): Height in pixels to which scan cross sections get resized.\n",
    "        width (int): Width in pixels to which scan cross sections get resized.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Tuple of lists of numpy arrays where the first list contains the raw data, is of length \n",
    "            N (total number of cross sections from the scan), and each element is a numpy array of shape\n",
    "            (height, width). The second list contains the segmented data and is of length N and\n",
    "            contains numpy arrays of shape (height, width, C) where C is the number of\n",
    "            pixel classes. By default C is 9. Class dimension is one-hot-encoded.\n",
    "    \n",
    "    \"\"\"\n",
    "    default_raw_pixel_classes = [0, 7, 8, 9, 45, 51, 52, 53, 68]\n",
    "    raw_images = []\n",
    "    segmentations = []    \n",
    "    scan_files = []\n",
    "    \n",
    "    print(\"====\")\n",
    "    print(processed_data_dir)\n",
    "    print(\"====\")\n",
    "    \n",
    "    for item in os.listdir(processed_data_dir):\n",
    "        item_path = os.path.join(processed_data_dir, item)\n",
    "        if os.path.isfile(item_path) and not item.startswith('.'):\n",
    "            scan_files.append(item)\n",
    "        \n",
    "    scan_files = sorted(scan_files)\n",
    "    \n",
    "    for file in scan_files:\n",
    "        print(file, end=' ')\n",
    "        if 'label' in file:\n",
    "            img = imread(os.path.join(processed_data_dir, file), flatten=True)\n",
    "        else:\n",
    "            img = load_sparse_csr(os.path.join(processed_data_dir, file)).toarray() \n",
    "        \n",
    "        img = pad_image(img, height, width)\n",
    "        if 'raw' in file:\n",
    "            raw_images.append(img)\n",
    "        elif 'label' in file:\n",
    "            encoded_img = one_hot_encode(img, default_raw_pixel_classes)\n",
    "            segmentations.append(encoded_img)\n",
    "    \n",
    "    return raw_images, segmentations\n",
    "            \n",
    "\n",
    "def save_seg_as_nifti(seg, target_dir, nii_data_dir):\n",
    "    '''\n",
    "    TODO: Fix to be compatible with predict_all_segs function, arbitrary scans.\n",
    "    '''\n",
    "    original_vol = nib.load(os.path.join(nii_data_dir, 'trial15_60_w1_volume_TRANS.nii'))\n",
    "    new_header = original_vol.header.copy()\n",
    "    new_nifti = nib.nifti1.Nifti1Image(seg, None, header=new_header)\n",
    "    nib.save(new_nifti, '/home/jessica/Documents/hart-seg-ml/predictedsegs/trial15_60_w1_first/trial15_60_w1_first_pred_seg.nii')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cross_sec(x, model, sess):\n",
    "    prediction = model.predict(sess, x)\n",
    "    pred_classes = np.argmax(prediction[0], axis=2)\n",
    "    return pred_classes\n",
    "\n",
    "def predict_whole_seg(X, model, sess):\n",
    "    '''\n",
    "    Todo: Crop the predictions. \n",
    "    '''\n",
    "    segmented = np.empty(X.shape[:3])\n",
    "    num_sections = X.shape[0]\n",
    "    for i in range(num_sections):\n",
    "        pred = predict_cross_sec(X[i:i+1], model, sess)\n",
    "        segmented[i] = pred\n",
    "        print(i, end=', ')\n",
    "    return segmented\n",
    "\n",
    "def predict_all_segs(to_segment_dir, save_dir, nii_data_dir, model, sess):\n",
    "    \"\"\"\n",
    "    Produce segmentations of arbitrary number of preprocessed scans and save them all as Nifti\n",
    "    files. Each preprocessed scan should be in separate subfolder. Names of folders containing \n",
    "    scan data should start with \"trial\".\n",
    "    \"\"\"\n",
    "    scan_paths = []\n",
    "    \n",
    "    for folder in os.listdir(to_segment_dir):\n",
    "        print(folder, end=' ')\n",
    "        if folder.startswith('trial'):\n",
    "            scan_path = os.path.join(to_segment_dir, folder)\n",
    "            scan_paths.append(scan_path)\n",
    "            \n",
    "    print(\"\")\n",
    "    \n",
    "    for scan_path in scan_paths:\n",
    "        raw_scan_data, ignore = load_data(scan_path)\n",
    "        print(scan_path, \":\", len(raw_scan_data), end=' ')\n",
    "        # segmented_scan = predict_whole_seg(raw_scan_data, model, sess)\n",
    "        # save_seg_as_nifti(segmented_scan, save_dir, nii_data_dir)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(models_dir, model_name):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, os.path.join(os.path.join(models_dir, model_name), model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_data_dir = \"/Users/nozik/Documents/HARTresearch/allrawnifti\"\n",
    "pipeline_test_dir = \"/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test\"\n",
    "ORIGINAL_DIMS = (482, 395)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/trial12_30_w3', '/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/trial15_60_w1']\n",
      "====\n",
      "/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/trial12_30_w3\n",
      "====\n",
      "0_label.png 0_raw.npz 10_label.png 10_raw.npz 11_label.png 11_raw.npz 12_label.png 12_raw.npz 13_label.png 13_raw.npz 14_label.png 14_raw.npz 15_label.png 15_raw.npz 16_label.png 16_raw.npz 17_label.png 17_raw.npz 18_label.png 18_raw.npz 19_label.png 19_raw.npz 1_label.png 1_raw.npz 20_label.png 20_raw.npz 21_label.png 21_raw.npz 22_label.png 22_raw.npz 23_label.png 23_raw.npz 24_label.png 24_raw.npz 25_label.png 25_raw.npz 26_label.png 26_raw.npz 27_label.png 27_raw.npz 28_label.png 28_raw.npz 29_label.png 29_raw.npz 2_label.png 2_raw.npz 30_label.png 30_raw.npz 3_label.png 3_raw.npz 4_label.png 4_raw.npz 5_label.png 5_raw.npz 6_label.png 6_raw.npz 7_label.png 7_raw.npz 8_label.png 8_raw.npz 9_label.png 9_raw.npz ====\n",
      "/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/trial15_60_w1\n",
      "====\n",
      "0_label.png 0_raw.npz 10_label.png 10_raw.npz 11_label.png 11_raw.npz 12_label.png 12_raw.npz 13_label.png 13_raw.npz 14_label.png 14_raw.npz 15_label.png 15_raw.npz 16_label.png 16_raw.npz 17_label.png 17_raw.npz 18_label.png 18_raw.npz 19_label.png 19_raw.npz 1_label.png 1_raw.npz 20_label.png 20_raw.npz 21_label.png 21_raw.npz 22_label.png 22_raw.npz 23_label.png 23_raw.npz 24_label.png 24_raw.npz 25_label.png 25_raw.npz 26_label.png 26_raw.npz 27_label.png 27_raw.npz 28_label.png 28_raw.npz 29_label.png 29_raw.npz 2_label.png 2_raw.npz 30_label.png 30_raw.npz 3_label.png 3_raw.npz 4_label.png 4_raw.npz 5_label.png 5_raw.npz 6_label.png 6_raw.npz 7_label.png 7_raw.npz 8_label.png 8_raw.npz 9_label.png 9_raw.npz "
     ]
    }
   ],
   "source": [
    "raw_data, seg_data = load_all_data(pipeline_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n",
      "(62, 512, 512)\n",
      "(62, 512, 512, 9)\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_data))\n",
    "print(len(seg_data))\n",
    "\n",
    "raw_data_arr = np.array(raw_data)\n",
    "seg_data_arr = np.array(seg_data)\n",
    "\n",
    "print(raw_data_arr.shape)\n",
    "print(seg_data_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "(482, 395)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1161423c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_img = raw_data_arr[0]\n",
    "print(example_img.shape)\n",
    "cropped_example = crop_cross_sec(example_img, 482, 395)\n",
    "print(cropped_example.shape)\n",
    "\n",
    "#plt.imshow(example_img)\n",
    "plt.imshow(cropped_example)\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store test_prediction_methods trial12_30_w3 trial15_60_w1 \n",
      "====\n",
      "/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/trial12_30_w3\n",
      "====\n",
      "0_label.png 0_raw.npz 10_label.png 10_raw.npz 11_label.png 11_raw.npz 12_label.png 12_raw.npz 13_label.png 13_raw.npz 14_label.png 14_raw.npz 15_label.png 15_raw.npz 16_label.png 16_raw.npz 17_label.png 17_raw.npz 18_label.png 18_raw.npz 19_label.png 19_raw.npz 1_label.png 1_raw.npz 20_label.png 20_raw.npz 21_label.png 21_raw.npz 22_label.png 22_raw.npz 23_label.png 23_raw.npz 24_label.png 24_raw.npz 25_label.png 25_raw.npz 26_label.png 26_raw.npz 27_label.png 27_raw.npz 28_label.png 28_raw.npz 29_label.png 29_raw.npz 2_label.png 2_raw.npz 30_label.png 30_raw.npz 3_label.png 3_raw.npz 4_label.png 4_raw.npz 5_label.png 5_raw.npz 6_label.png 6_raw.npz 7_label.png 7_raw.npz 8_label.png 8_raw.npz 9_label.png 9_raw.npz /Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/trial12_30_w3 : 31 ====\n",
      "/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/trial15_60_w1\n",
      "====\n",
      "0_label.png 0_raw.npz 10_label.png 10_raw.npz 11_label.png 11_raw.npz 12_label.png 12_raw.npz 13_label.png 13_raw.npz 14_label.png 14_raw.npz 15_label.png 15_raw.npz 16_label.png 16_raw.npz 17_label.png 17_raw.npz 18_label.png 18_raw.npz 19_label.png 19_raw.npz 1_label.png 1_raw.npz 20_label.png 20_raw.npz 21_label.png 21_raw.npz 22_label.png 22_raw.npz 23_label.png 23_raw.npz 24_label.png 24_raw.npz 25_label.png 25_raw.npz 26_label.png 26_raw.npz 27_label.png 27_raw.npz 28_label.png 28_raw.npz 29_label.png 29_raw.npz 2_label.png 2_raw.npz 30_label.png 30_raw.npz 3_label.png 3_raw.npz 4_label.png 4_raw.npz 5_label.png 5_raw.npz 6_label.png 6_raw.npz 7_label.png 7_raw.npz 8_label.png 8_raw.npz 9_label.png 9_raw.npz /Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/trial15_60_w1 : 31 "
     ]
    }
   ],
   "source": [
    "train_data_dir = \"/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/test_prediction_methods/train_on_these\"\n",
    "scans_to_segment_dir = \"/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/test_prediction_methods/predict_these\"\n",
    "seg_results_dir = \"/Users/nozik/Documents/HARTresearch/unet/hart-seg-ml/pipeline_test/test_prediction_methods/train_on_these/put_results_here\"\n",
    "\n",
    "predict_all_segs(pipeline_test_dir, seg_results_dir, None, None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: rename loading functions to something like load trials; check that get raw pixel classes still works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
