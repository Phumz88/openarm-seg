{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2961736824169864948\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "sys.path.append('src/')\n",
    "import nn\n",
    "import process_data\n",
    "import cv2\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy.sparse\n",
    "from scipy.misc import imrotate\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage import rotate\n",
    "from skimage import exposure\n",
    "from skimage.io import imread, imsave\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "print(local_device_protos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(L, class_labels):\n",
    "    \"\"\"\n",
    "    2D array (image) of segmentation labels -> .npy\n",
    "    # One Hot Encode the label 2d array -> .npy files with dim (h, w, len(class_labels))\n",
    "    # num classes will be 8? but currently dynamically allocated based on num colors in all scans.\n",
    "    \"\"\"\n",
    "    h, w = L.shape  # Should be 482, 395\n",
    "    try:\n",
    "        encoded = np.array([list(map(class_labels.index, L.flatten()))])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    L = encoded.reshape(h, w)\n",
    "\n",
    "    Lhot = np.zeros((L.shape[0], L.shape[1], len(class_labels)))\n",
    "    for i in range(L.shape[0]):\n",
    "        for j in range(L.shape[1]):\n",
    "            Lhot[i,j,L[i,j]] = 1\n",
    "    return Lhot  # Should be shape (482, 395, 9)\n",
    "    \n",
    "def uncode_one_hot(npy_file):\n",
    "    \"\"\"\n",
    "    .npy file -> JPEG\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "#         if image.ndim == 2:\n",
    "#             plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()\n",
    "    \n",
    "def load_sparse_csr(filename):\n",
    "    # Sparse matrix reading function to read our raw .npz files\n",
    "    assert filename.endswith('.npz')\n",
    "    loader = np.load(filename)  # filename must end with .npz\n",
    "    return scipy.sparse.csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                      shape=loader['shape'])\n",
    "\n",
    "def get_raw_pixel_classes():\n",
    "    import nibabel as nib\n",
    "    base_data_dir = \"/Users/kireet/ucb/HART Research/Muscle Segmentation/raw_nifti_scan\"\n",
    "    example_segmentation = os.path.join(base_data_dir, 'trial10_30_w1_seg2_TRANS.nii')\n",
    "    scan_voxel = nib.load(example_segmentation)\n",
    "    struct_arr = scan_voxel.get_data()\n",
    "    n, h, w = struct_arr.shape\n",
    "    class_labels = list(np.unique(struct_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kireet/ucb/HART Research/Muscle Segmentation/cleaned_images_test/trial10_30_w1\n"
     ]
    }
   ],
   "source": [
    "raw_pixel_classes =[0, 7, 8, 9, 45, 51, 52, 53, 68]  # Expected raw grayscale values for each pixel\n",
    "directory = \"/Users/kireet/ucb/HART Research/Muscle Segmentation/cleaned_images_test\"\n",
    "filenames = []  # Stores all filenames\n",
    "raw_images = []  # Stores X (Raw cross section images as 2D np.ndarray)\n",
    "segmentations = []  # Stores Y (Labeled/Segmented image as one-hot-encoded NumClasses-D np.ndarray)\n",
    "\n",
    "for folder in os.listdir(directory):\n",
    "    class_labels = set()\n",
    "    if not folder.startswith('.'):\n",
    "        path = os.path.join(directory, folder)\n",
    "        print(path)\n",
    "        files = sorted([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')])\n",
    "        \n",
    "        # Class label sanity check\n",
    "        for f in files:\n",
    "            if 'label' in f:\n",
    "                img = imread(os.path.join(path, f), flatten=True)\n",
    "                class_labels = class_labels.union(np.unique(img))\n",
    "        if not class_labels.issubset(raw_pixel_classes):\n",
    "            print(\"Class labels found in labeled images do not match the expected classes for scan {}\".format(folder))\n",
    "            print(\"Expected {}\".format(raw_pixel_classes))\n",
    "            print(\"Received {}\".format(sorted(class_labels)))\n",
    "            break\n",
    "        \n",
    "        # Sanity image read and show some images in pairs (play with the range inputs)\n",
    "#         for f in range(0, len(files), 2):\n",
    "#             label_name = files[f]\n",
    "#             raw_name = files[f+1]\n",
    "#             label_img = imread(os.path.join(path, label_name), flatten=True)\n",
    "#             raw_img = load_sparse_csr(os.path.join(path, raw_name)).toarray()  # Load sparse csr mat img -> to 2D numpy array\n",
    "#             show_images([label_img, raw_img], titles=[label_name, raw_name])\n",
    "        \n",
    "        # Set up Datasets (X, Y) pairs of data ->\n",
    "        # files are sorted by the name: either '#_label' or '#_raw'\n",
    "        for f in files:\n",
    "            if 'raw' in f:\n",
    "                raw_images.append(img)\n",
    "            elif 'label' in f:\n",
    "                encoded_img = one_hot_encode(img, raw_pixel_classes)\n",
    "                segmentations.append(encoded_img)\n",
    "            filenames.append(os.path.join(folder, f))\n",
    "# print(filenames)\n",
    "\n",
    "#     image = imresize(imread(directory + folder + '/' + folder + '.jpg', flatten = True),(h, w))\n",
    "#     images.append(image)\n",
    "#     filenames.append(folder)\n",
    "#     seg = np.load(directory+folder+'/seg.npy')\n",
    "#     temp = np.zeros((h,w,1))\n",
    "#     temp[:,:,1] = imresize(seg[:,:,1],(h,w), interp='nearest')/255.0\n",
    "#     segmentations.append(temp)\n",
    "            \n",
    "# images = np.array(images)\n",
    "# segmentations = np.round(np.array(segmentations)).astype('uint8')\n",
    "\n",
    "\n",
    "# study_num = int(2)\n",
    "# train_lst = np.load('data/splits/train_lst_' + str(study_num) + '.npy')\n",
    "# val_lst = np.load('data/splits/val_lst_' + str(study_num) + '.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training, Cross Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 482, 395, 1)\n",
      "(2, 482, 395, 1)\n",
      "(6, 482, 395, 9)\n",
      "(2, 482, 395, 9)\n",
      "\n",
      "(6, 512, 512, 1)\n",
      "(2, 512, 512, 1)\n",
      "(6, 512, 512, 9)\n",
      "(2, 512, 512, 9)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: Same Scan cannot be used across Train, Validation and Test sets\n",
    "TODO: Different weight conditions and angles may be used to segment other raw_scans\n",
    "TODO: Bounding Box, image resizing, padding edges\n",
    "\"\"\"\n",
    "# raw_images holds our X data\n",
    "# segmentations holds out Y data\n",
    "h, w = 482, 395\n",
    "x_train, y_train = [], []\n",
    "x_val, y_val = [], []\n",
    "x_test, y_test = [], []\n",
    "\n",
    "percent_train, percent_val, percent_test = 70, 0, 30\n",
    "num_train = np.round(len(raw_images) * percent_train/100).astype(np.int)\n",
    "num_val = np.round(num_train + len(raw_images) * percent_val/100).astype(np.int)\n",
    "num_test = np.round(num_val + len(raw_images) * percent_test/100).astype(np.int)\n",
    "\n",
    "assert len(raw_images) == len(segmentations)\n",
    "rand_indices = list(np.random.choice(len(raw_images), len(raw_images), replace=False))\n",
    "\n",
    "for i in rand_indices[:num_train]:\n",
    "    x_train.append(raw_images[i])\n",
    "    y_train.append(segmentations[i])\n",
    "for j in rand_indices[num_train:num_val]:\n",
    "    x_val.append(raw_images[j])\n",
    "    y_val.append(segmentations[j])\n",
    "for k in rand_indices[num_val:num_test]:\n",
    "    x_test.append(raw_images[k])\n",
    "    y_test.append(segmentations[k])\n",
    "                \n",
    "x_train = np.array(x_train).reshape((len(x_train),h,w,1))\n",
    "x_test = np.array(x_test).reshape((len(x_test),h,w,1))\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Fix data padding to create square 482 by 482 matrix\n",
    "npad = ((0, 0), (15, 15), (59, 58), (0, 0))\n",
    "x_train = np.pad(x_train, pad_width=npad, mode='constant', constant_values=0)\n",
    "x_test = np.pad(x_test, pad_width=npad, mode='constant', constant_values=0)\n",
    "y_train = np.pad(y_train, pad_width=npad, mode='constant', constant_values=0)\n",
    "y_test = np.pad(y_test, pad_width=npad, mode='constant', constant_values=0)\n",
    "\n",
    "print()\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# (x, 482, 482, 1)\n",
    "# (x, 482, 482, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h, w = 512, 512\n",
    "class Unet(object):        \n",
    "    def __init__(self, mean, weight_decay, learning_rate, label_dim = 8, dropout = 0.9):\n",
    "        self.x_train = tf.placeholder(tf.float32, [None, h, w, 1])\n",
    "        self.y_train = tf.placeholder(tf.float32, [None, h, w, 9])\n",
    "        self.x_test = tf.placeholder(tf.float32, [None, h, w, 1])\n",
    "        self.y_test = tf.placeholder(tf.float32, [None, h, w, 9])\n",
    "        \n",
    "        self.label_dim = label_dim\n",
    "        self.weight_decay = weight_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.output = self.unet(self.x_train, mean, keep_prob=self.dropout)\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.output, labels = self.y_train))\n",
    "        self.opt = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "        \n",
    "        self.pred = self.unet(self.x_test, mean, reuse = True, keep_prob = 1.0)\n",
    "        self.loss_summary = tf.summary.scalar('loss', self.loss)\n",
    "    \n",
    "    # Gradient Descent on mini-batch\n",
    "    def fit_batch(self, sess, x_train, y_train):\n",
    "        _, loss, loss_summary = sess.run((self.opt, self.loss, self.loss_summary), feed_dict={self.x_train: x_train, self.y_train: y_train})\n",
    "        return loss, loss_summary\n",
    "    \n",
    "    def predict(self, sess, x):\n",
    "        prediction = sess.run((self.pred), feed_dict={self.x_test: x})\n",
    "        return prediction\n",
    "\n",
    "    \n",
    "    def unet(self, input, mean, keep_prob = 0.9, reuse = None):\n",
    "        with tf.variable_scope('vgg', reuse=reuse):\n",
    "            input = input - mean\n",
    "            pool_ = lambda x: nn.max_pool(x, 2, 2)\n",
    "            conv_ = lambda x, output_depth, name, padding = 'SAME', relu = True, filter_size = 3: nn.conv(x, filter_size, output_depth, 1, self.weight_decay, \n",
    "                                                                                                           name=name, padding=padding, relu=relu)\n",
    "            deconv_ = lambda x, output_depth, name: nn.deconv(x, 2, output_depth, 2, self.weight_decay, name=name)\n",
    "            \n",
    "            conv_1_1 = conv_(input, 64, 'conv1_1')\n",
    "            conv_1_2 = conv_(conv_1_1, 64, 'conv1_2')\n",
    "\n",
    "            pool_1 = pool_(conv_1_2)\n",
    "\n",
    "            conv_2_1 = conv_(pool_1, 128, 'conv2_1')\n",
    "            conv_2_2 = conv_(conv_2_1, 128, 'conv2_2')\n",
    "\n",
    "            pool_2 = pool_(conv_2_2)\n",
    "\n",
    "            conv_3_1 = conv_(pool_2, 256, 'conv3_1')\n",
    "            conv_3_2 = conv_(conv_3_1, 256, 'conv3_2')\n",
    "\n",
    "            pool_3 = pool_(conv_3_2)\n",
    "\n",
    "            conv_4_1 = conv_(pool_3, 512, 'conv4_1')\n",
    "            conv_4_2 = conv_(conv_4_1, 512, 'conv4_2')\n",
    "\n",
    "            pool_4 = pool_(conv_4_2)\n",
    "\n",
    "            conv_5_1 = conv_(pool_4, 1024, 'conv5_1')\n",
    "            conv_5_2 = conv_(conv_5_1, 1024, 'conv5_2')\n",
    "            \n",
    "            pool_5 = pool_(conv_5_2)\n",
    "            \n",
    "            conv_6_1 = tf.nn.dropout(conv_(pool_5, 2048, 'conv6_1'), keep_prob)\n",
    "            conv_6_2 = tf.nn.dropout(conv_(conv_6_1, 2048, 'conv6_2'), keep_prob)\n",
    "            \n",
    "            up_7 = tf.concat([deconv_(conv_6_2, 1024, 'up7'), conv_5_2], 3)  # Error here rn\n",
    "            \n",
    "            conv_7_1 = conv_(up_7, 1024, 'conv7_1')\n",
    "            conv_7_2 = conv_(conv_7_1, 1024, 'conv7_2')\n",
    "\n",
    "            up_8 = tf.concat([deconv_(conv_7_2, 512, 'up8'), conv_4_2], 3)\n",
    "            \n",
    "            conv_8_1 = conv_(up_8, 512, 'conv8_1')\n",
    "            conv_8_2 = conv_(conv_8_1, 512, 'conv8_2')\n",
    "\n",
    "            up_9 = tf.concat([deconv_(conv_8_2, 256, 'up9'), conv_3_2], 3)\n",
    "            \n",
    "            conv_9_1 = conv_(up_9, 256, 'conv9_1')\n",
    "            conv_9_2 = conv_(conv_9_1, 256, 'conv9_2')\n",
    "\n",
    "            up_10 = tf.concat([deconv_(conv_9_2, 128, 'up10'), conv_2_2], 3)\n",
    "            \n",
    "            conv_10_1 = conv_(up_10, 128, 'conv10_1')\n",
    "            conv_10_2 = conv_(conv_10_1, 128, 'conv10_2')\n",
    "\n",
    "            up_11 = tf.concat([deconv_(conv_10_2, 64, 'up11'), conv_1_2], 3)\n",
    "            \n",
    "            conv_11_1 = conv_(up_11, 64, 'conv11_1')\n",
    "            conv_11_2 = conv_(conv_11_1, 64, 'conv11_2')\n",
    "            \n",
    "            conv_12 = conv_(conv_11_2, 9, 'conv12_2', filter_size = 1, relu = False)\n",
    "            return conv_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "mean = 24\n",
    "weight_decay = 1e-6\n",
    "learning_rate = 1e-4\n",
    "label_dim = 8\n",
    "maxout = False\n",
    "\n",
    "# Create TF graph and initialize variables\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "model = Unet(mean, weight_decay, learning_rate, label_dim , dropout = 0.5)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restore old model\n",
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess, '/media/deoraid03/jeff/models/a4c_experiments/deep_256_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Iter 5 | Loss: 1.694 | Data: 5/6 | Time 1.2e+02     \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/nn.py:131: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  dice = 2*np.sum(overlap)/(np.sum(gt) + np.sum(pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Iter 5 | Loss: 1.7 | Acc: [ 0.       nan  0.     0.     0.     0.696  0.014  0.   ] | Time 1.2e+02     \r\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "nn.train(sess, model, x_train, y_train, x_test, y_test, epochs = 1, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, nan, 0.0, 0.0, 0.0, 0.69592735277930651, 0.013969732246798603, 0.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IOU Accuracies for each label\n",
    "nn.validate(sess, model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "# saver = tf.train.Saver()\n",
    "# saver.save(sess, '/media/deoraid03/jeff/models/a4c_experiments/deep_256_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
